# Data loading

```{r}
library(tidyverse)
library(glue)
library(here)
library(mirt)
library(ggrepel)

source(here("02_score_data","irt_helpers.R"))
source(here("03_summaries", "plotting_helper.R"))

sites <- c("co_pilot", "de_pilot")

task_data_nested <- sites |>
  set_names() |>
  map(\(s) read_rds(here(glue("01_processed_data/{s}/task_data_nested.rds")))) |>
  list_rbind(names_to = "site")

task_data_combined <- task_data_nested |>
  select(-task_id) |>
  unnest(data) 

tom <- filter(task_data_combined, 
              task_id %in% c("theory-of-mind","emotion-reasoning"))
```

Get ages. 

```{r}
participants <- sites |>
  set_names() |>
  map(\(s) read_rds(here(glue("00_prepped_data/{s}/participants.rds")))) |>
  list_rbind(names_to = "site")

run_ages <- participants |>
  select(user_id, ages) |>
  unnest(ages)

tom <- left_join(tom, run_ages)
```

# Sumscore approach

First plot sumscores.

```{r}
tom_runs <- tom |>
  group_by(site, user_id, run_id, task_id) |>
  summarise(correct = mean(correct), 
            age = mean(age))

ggplot(tom_runs, aes(x = age, y = correct)) + 
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm") +
  facet_grid(site ~ task_id)
```

Sites together. 

```{r}
ggplot(tom_runs, aes(x = age, y = correct, col = site)) + 
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm") +
  facet_wrap(~ task_id)
```

Just for kicks, let's look at correlations between TOM and emotion reasoning. 

```{r}
tom_runs |>
  pivot_wider(names_from = "task_id", values_from = "correct") |>
  ggplot(aes(x = `theory-of-mind`, y = `emotion-reasoning`)) + 
  geom_jitter(height = .02, width = .02, alpha = .5) + 
  geom_smooth(method = "lm") + 
  facet_wrap(~site)
```


Note there are some substantial task differences between CO and DE that make these hard to interpret. 

```{r}
#| fig.height: 14
#| fig.width: 6
tom_items <- tom |>
  group_by(site, item_id) |>
  summarise(correct = mean(correct)) |>
  ungroup() |>
  mutate(item_id = fct_reorder(item_id, correct))

ggplot(tom_items, aes(x = item_id, y = correct)) + 
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm") +
  coord_flip() + 
  facet_grid(site ~ .)

# ggsave("~/Desktop/item_difficulties.png")
```


# IRT approach

Let's move to models. 

```{r}

tom_plus_er_prepped <- tom |>
  nest() |>
  mutate(data_filtered = map(data, \(df) df |> filter_repeat_runs() |>
                               dedupe_items() |> remove_no_var_items()),
         data_prepped = map(data_filtered, to_mirt_shape)) |>
  # pull out chance values
  mutate(guess = map(data_filtered, # TODO: check that this gives correct order
                     \(df) df |> distinct(item_inst, chance) |> pull(chance)))
# 
# single_task_prepped <- tom |>
#   group_by(task_id) |>
#   nest() |>
#   mutate(data_filtered = map(data, \(df) df |> filter_repeat_runs() |>
#                                dedupe_items() |> remove_no_var_items()),
#          data_prepped = map(data_filtered, to_mirt_shape)) |>
#   # pull out chance values
#   mutate(guess = map(data_filtered, # TODO: check that this gives correct order
#                      \(df) df |> distinct(item_inst, chance) |> pull(chance)))

item_types <- c("Rasch", "2PL") #, "3PL") # set of parameterizations
model_types <- c(1,2) #, 2) # set of dimensionalities
# model_types <- c(1) # set of dimensionalities

# add arguments for model fitting to data
tom_plus_er_data_args <- tom_plus_er_prepped |>
  # duplicate rows per dimensionality x parameterization
  expand_grid(model_type = model_types, item_type = item_types) |>
  # generate model string with item constraints + dimensionality
  mutate(model_str = pmap_chr(list(data, data_prepped, item_type, model_type),
                              generate_model_str))

# single_task_data_args <- single_task_prepped |>
#   # duplicate rows per dimensionality x parameterization
#   expand_grid(model_type = model_types, item_type = item_types) |>
#   # generate model string with item constraints + dimensionality
#   mutate(model_str = pmap_chr(list(data, data_prepped, item_type, model_type),
#                               generate_model_str))
```


```{r}
# single_task_models <- single_task_data_args |>
#   mutate(mod = pmap(list(row_number(), data_prepped, item_type, model_str,
#                          model_type, guess),
#                     fit_mirt))

tom_plus_er_models <- tom_plus_er_data_args |>
  mutate(mod = pmap(list(row_number(), data_prepped, item_type, model_str,
                         model_type, guess),
                    fit_mirt))
```

```{r}
# get each model's coefs, scores, BIC
tom_plus_er_results <- tom_plus_er_models |>
  mutate(coefs = map(mod, mirt_coefs),
         scores = pmap(list(mod, data_filtered, data_prepped), mirt_scores),
         bic = map_dbl(mod, mirt_bic))

# best fitting model for each task
tom_plus_er_best <- tom_plus_er_results |>
  filter(bic == min(bic)) |>
  ungroup()
# select(site, task_id, item_type, model_type, coefs, scores)

# scores from best fitting models
tom_plus_er_scores <- tom_plus_er_best |>
  select(item_type, model_type, scores) |>
  unnest(scores) |>
  mutate(#item_type = fct_recode(item_type, "1PL" = "Rasch"),
    metric_type = glue("ability ({item_type}-{model_type})")) |>
  select(user_id, run_id, metric_type, metric_value = ability)
```

```{r}
select(tom_plus_er_results, model_type, item_type, bic)
```





```{r, eval=FALSE}
# get each model's coefs, scores, BIC
# single_task_results <- single_task_models |>
#   mutate(coefs = map(mod, mirt_coefs),
#          scores = pmap(list(mod, data_filtered, data_prepped), mirt_scores),
#          bic = map_dbl(mod, mirt_bic))
# 
# # best fitting model for each task
# single_task_best <- single_task_results |>
#   group_by(task_id)
#   filter(bic == min(bic)) |>
#   ungroup()
# # select(site, task_id, item_type, model_type, coefs, scores)
# 
# # scores from best fitting models
# sds_scores <- sds_best |>
#   select(item_type, model_type, scores) |>
#   unnest(scores) |>
#   mutate(#item_type = fct_recode(item_type, "1PL" = "Rasch"),
#     metric_type = glue("ability ({item_type}-{model_type})")) |>
#   select(user_id, run_id, metric_type, metric_value = ability)
```

## Analysis


```{r}
tom_coefs <- tom_plus_er_best$coefs[[1]]
tom_coefs$item <- fct_reorder(tom_coefs$item, tom_coefs$d)
ggplot(tom_coefs, aes(x = a1, y = -d)) + 
  ylab("Difficulty") +
  geom_point() + 
  coord_flip() +
  geom_label_repel(aes(label = item), max.overlaps = 20, size = 2)
```

outliers by 2PL slope


```{r}

tom_outliers_a1 <- tom_coefs |> filter(abs(a1) > 3) 

ggplot(tom_coefs |>
         select(-g,-u) |>
         pivot_longer(a1:d, names_to = "parameter", values_to = "value"), 
       aes(x = value)) + 
  geom_histogram(binwidth = 1) + 
  facet_wrap(~parameter)
```


```{r}
#| fig.height: 6
ggplot(tom_coefs, aes(x = item, y= -d)) + 
  geom_point() + 
  coord_flip() +
  xlab("Difficulty")
```

```{r}
tom_runs_wide <- tom_runs |> 
  select(-run_id) |>
  pivot_wider(names_from = "task_id", values_from = "correct", 
              id_cols = c("site","user_id","age"))

tom_runs_scores <- left_join(tom_runs_wide, select(tom_plus_er_best$scores[[1]], -run_id))
                             
ggplot(tom_runs_scores, aes(x = age, y = ability)) + 
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm") + 
  facet_wrap(~site)
```

```{r}
ggplot(tom_runs_scores, aes(x = `theory-of-mind`, y = ability)) + 
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm") + 
  facet_wrap(~site)
```


```{r}
# marginal reliabilities
mrot_marginal_rasch <- mrot_submods_rasch |> map(marginal_rxx) # why are these the same?
mrot_marginal_2pl <- mrot_submods_2pl |> map(marginal_rxx) # why are these the same?
```







