---
title: "TOM IRT Models"
author: "Adani Abutto"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: cosmo
    highlight: tango

header-includes:
    - \usepackage{setspace}\doublespacing
---

# Background Info

Info on data structure:

<https://docs.google.com/document/d/1v-nqBxk3R9cSbvJshaBsWQp7KUtBjQSdMNXHw9NDfKg/edit?tab=t.0#heading=h.c60fcjq089m>

TOM item bank:

<https://docs.google.com/spreadsheets/d/11qBJS3RZn0wuLY5UcwoiVy8q-DFhXQJzfJv1jxDEu3s/edit?gid=1557292668#gid=1557292668>

Automated runs through tasks:

<https://crowdin.com/project/levantetranslations/screenshots>

Airtables:

[airtable.com/appe2p0S3xk4DL2qc/shrSnlS1BwADsrBGq](airtable.com/appe2p0S3xk4DL2qc/shrSnlS1BwADsrBGq)

<https://airtable.com/appIk9XNTZZns1F1F/shr50bi3Y8MeNCjQE>

------------------------------------------------------------------------------------------

# Setup

```{r setup, include = F, message = F, warning = F}

# load relevant libraries and functions
library(here)
library(glue)          # for working with images
library(png)           
library(grid)
library(patchwork)
library(DT)            # for nicer tables
library(mirt)          # for IRT models
library(tidyverse)     # for everything else
library(dplyr)

# set default code chunk options
knitr::opts_chunk$set(echo = T, warning = F, message = F)

# set default plot theme 
theme_set(theme_classic() + 
            theme(text = element_text(size = 32))) 

# fix print width for knitted doc
options(width = 70)

# set random seed
set.seed(1)

```

First, let's fetch the data.

```{r}

# read in the data
tom_data_long =
  read_rds(here("01_fetched_data/task_data_nested.rds")) %>%
  # keep only tom tasks
  filter(item_task == "tom",
         # keep only Canada, Colombia, Germany
         site %in% c("ca_pilot", "co_pilot", "de_pilot")) %>%
  # unnest
  unnest(data) %>%
  # filter out missing item uids
  filter(!is.na(item_uid)) %>%
  # convert booleans to numeric
  mutate(correct = unlist(correct)) %>%
  mutate(correct = case_when(correct == T ~ 1,
                             correct == F ~ 0,
                             TRUE ~ NA_real_))

# add age information
df.age =
  read_rds(here(glue("01_fetched_data/run_data.rds"))) %>%
  select(run_id, age)

tom_data_long =
  tom_data_long %>%
  left_join(df.age, by = "run_id")

```

Let's have a look at key aspects of the data:

```{r}

# number of subjects (672)
Hmisc::describe(tom_data_long$user_id)

# number of runs (792)
Hmisc::describe(tom_data_long$run_id)

# number of items (38)
Hmisc::describe(tom_data_long$item_uid)

# number of item groups (6)
Hmisc::describe(tom_data_long$item_group)

# test sites (3)
Hmisc::describe(tom_data_long$dataset)

```

And then let's run simple item and subject statistics:

```{r}

# % correct per item per site
tom_data_long %>%
  group_by(site, item_uid) %>%
  summarise(n = n(),
            mean_age = round(mean(age, na.rm = T),
                             2),
            n_correct = sum(correct == 1),
            pct_correct = round(mean(correct == 1), 3)) %>%
  arrange(site, pct_correct) %>%
  datatable()

# subject-level descriptives
tom_data_long %>%
  group_by(site, user_id, run_id) %>%
  summarise(correct = round(mean(correct, na.rm = T),
                            2), 
            age = round(mean(age, na.rm = T),
                        2),
            n_items = n_distinct(item_uid)) %>%
  datatable()

```

We see that there are **38 items** total, clustered into **6** **item groups** (deception,
interpretation, moral reasoning, reality/false belief, reference, and second order).

There are also **three test sites: CA, CO, and DE**, but not all test sites have data for
all 38 items. That's how we end up with 102 table entries (rather than the full 3\*38 =
114).

```{r}

tom_data_long %>%
  distinct(site, item_uid) %>%
  count(site,
        name = "n_items_with_data")

```

Now let's also check if there are any items for which particular sites have NO data:

```{r}

tom_data_long %>%
  count(site, item_uid) %>%
  pivot_wider(names_from = site,
              values_from = n,
              values_fill = 0) %>%
  arrange(across(everything(), ~ .x == 0,
                 .names = "missing_{.col}")) %>%
  datatable()

```

There are **7 items for which this is true**. We will need to account for this in our
model code.

Now, for each of our 38 (-7) items, we have **four different IRT models** we want to run:

1.  1PL/Rasch model
2.  1PL/Rasch model but with configural scoring
3.  2PL model
4.  2PL model but with configural scoring

With these, we will obtain **item difficulty and item discrimination** for each of our
items.

------------------------------------------------------------------------------------------

# IRT Models

As a sanity check, let's plot % correct per item across age:

```{r}

tom_data_long %>%
  ggplot(aes(x = age,
             y = correct,
             color = site)) +
  geom_point(alpha = 0.3, size = 1) +
  geom_smooth(method = "lm", se = T) +
  facet_wrap(~ item_uid,
             ncol = 6) +
  scale_y_continuous(limits = c(0, 1),
                     labels = scales::percent) +
  labs(x = "Age (years)",
       y = "% correct",
       color = "Site",
       title = "% correct by Item, Age, and Site") +
  theme_classic(base_size = 8) +
  theme(legend.position = "bottom")

```

Looks reasonable. Now let's prep the IRT data:

```{r}

# first, let's create a wide-format data frame
run_group_df =
  tom_data_long %>%
  distinct(run_id, site)

tom_irt_data =
  tom_data_long %>%
  # keep only relevant cols
  select(user_id, run_id, site, item, item_uid,
         item_group, timestamp, trial_id, response, answer, correct) %>%
  # if there are multiple responses for the same item in a single run, keep only the *last* response for each child
  arrange(run_id, item_uid) %>%
  group_by(run_id, item_uid) %>%
  slice_tail(n = 1) %>%
  # pivot to wide format
  ungroup() %>%
  pivot_wider(id_cols = run_id,
              names_from = item_uid,
              values_from = correct) %>%
  left_join(run_group_df, by = "run_id")

# now, before we can run our models, we need to exclude two types of items:

# 1) for any model: items with no variance
novar_items =
  c("tom_second_order_reality_check_2")

# 2) for multigroup models: items that are not shared across sites (i.e., for which some sites have no data)
nonshared_items =
  tom_data_long %>%
  count(site, item_uid) %>%
  pivot_wider(names_from = site, values_from = n, values_fill = 0) %>%
  # grab the items ones with 0 responses in any of the sites
  filter(if_any(everything(), ~ .x == 0)) %>%
  pull(item_uid)

# create new dfs in which these items are removed
items_to_remove =
  setdiff(nonshared_items, novar_items)

df.single =
  tom_irt_data %>%
  select(-(novar_items))

df.multigroup =
  tom_irt_data %>%
  select(-(items_to_remove))

```

Now let's create a response matrix for our IRT models:

```{r}

# keep only cols with correct/incorrect vals (1 and 0)
response_matrix_single =
  df.single %>%
  column_to_rownames("run_id") %>%
  select(-c(site)) %>%
  as.data.frame()

response_matrix_multigroup =
  df.multigroup %>%
  column_to_rownames("run_id") %>%
  select(-c(site)) %>%
  as.data.frame()

# create group vector with site information for multigroup model
group_vec =
  df.multigroup %>%
  distinct(run_id, site) %>%
  filter(run_id %in% rownames(response_matrix_multigroup)) %>%
  arrange(match(run_id, rownames(response_matrix_multigroup))) %>%
  pull(site)

```

Now let's prep our functions for running our IRT models.

```{r}

fit_irt_model =
  function(tom_irt_data_clean, model_type = "Rasch", group_vec = NULL) {
    if (!is.null(group_vec)) {
      model =
        # configural multigroup model
        multipleGroup(data = response_matrix_multigroup,
                      model = 1, # unidimensional
                      group = group_vec,
                      itemtype = model_type,
                      invariance = c(colnames(response_matrix_multigroup),
                                     "free_means", "free_var"), # group means and variance can vary, but item parameters are fixed
                      verbose = T,
                      technical = list(NCYCLES = 5000))
      
      } else
        {
          # pooled model
          model =
            mirt(data = response_matrix_multigroup,
                 model = 1, # unidimensional
                 itemtype = model_type,
                 technical = list(NCYCLES = 5000),
                 verbose = T)
          }
    return(model)
    }

```

Now, using the function we defined above, let's run our four models for all of the items:

```{r}

# fit 1PL Rasch model, nonconfigural
mod_rasch =
  fit_irt_model(df.single,
                model_type = "Rasch")

```

```{r}

# fit 2PL model, nonconfigural
mod_2pl =
  fit_irt_model(df.single,
                model_type = "2PL")

```

```{r}

# fit 1 PL Rasch model, *configural*
mod_rasch_configural =
  fit_irt_model(df.multigroup,
                model_type = "Rasch",
                group_vec = group_vec)

```

```{r}

# fit 2 PL Rasch model, *configural*
mod_2pl_configural =
  fit_irt_model(df.multigroup,
                model_type = "2PL",
                group_vec = group_vec)

```

```{r}

# create function to extract parameters for plotting
item_params = function(model, model_name = "unknown_model") {
  coefs_raw = coef(model, simplify = F)

  if ("GroupPars" %in% names(coefs_raw)) {
    group_names = setdiff(names(coefs_raw), c("GroupPars", "means", "cov"))

    map_dfr(group_names, function(g) {
      coefs = coefs_raw[[g]]
      if (is.null(coefs) || nrow(coefs) == 0) return(tibble())

      tibble(
        item_uid = rownames(coefs),
        a = coefs[, "a1"],
        d = coefs[, "d"],
        b = -coefs[, "d"] / coefs[, "a1"],
        site = g,
        model = model_name
      )
    })

  } else {
    coefs = coefs_raw$items
    if (is.null(coefs) || nrow(coefs) == 0) return(tibble())

    tibble(
      item_uid = rownames(coefs),
      a = coefs[, "a1"],
      d = coefs[, "d"],
      b = -coefs[, "d"] / coefs[, "a1"],
      site = "pooled",
      model = model_name
    )
  }
}

```

Then, let's grab the parameters for each item and plot them.

```{r}

# grab parameters
item_params_all =
  bind_rows(item_params(mod_rasch,
                        "rasch"),
            item_params(mod_2pl,
                        "2pl"),
            item_params(mod_rasch_configural,
                        "rasch_configural"),
            item_params(mod_2pl_configural,
                        "2pl_configural"))

```

Let's print a big table with item difficulties and item discriminations, sorted by model.

Higher discrimination values are better. For difficulty, lower value means easier item,
higher value means harder item.

***TODO 1: INCLUDE MODEL BIC AND FIX ERRONEOUS ITEM_UID ASSIGNMENT***

***TODO 2: WHY DO CONFIGURAL MODELS NOT SHOW UP?***

```{r}

item_params_all %>%
  select(item_uid, site, model, a, b) %>%
  mutate(across(c(a, b), ~ round(.x, 3))) %>%
  rename(discr = a,
         diff = b) %>%
  arrange(model, site, diff) %>%
  datatable()

```

Just item difficulties by model:

```{r}

# plot item difficulties for each item, faceted by model and site
ggplot(item_params_all,
       aes(x = site,
           y = b,
           color = model,
           group = model)) +
  geom_point(position = position_dodge(width = 0.1),
             size = 2.5) +
  labs(title = "Item Difficulties by Model",
       y = "Difficulty (b)",
       x = "Item") +
  ylim(-10, 10) +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  coord_flip()

```

Just item discrimination by model (discrimination is fixed for Rasch model, so no variance
there):

```{r}

# plot item discrimination for each item, faceted by model and site
ggplot(item_params_all,
       aes(x = site,
           y = a,
           color = model,
           group = model)) +
  geom_point(position = position_dodge(width = 0.1),
             size = 2.5) +
  labs(title = "Item Discrimination by Model",
       y = "Discrimination (a)",
       x = "Item") +
  ylim(-10, 10) +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  coord_flip()

```

***TODO: Plot ICCs***

```{r}



```
