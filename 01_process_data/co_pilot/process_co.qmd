```{r load-data}
library(tidyverse)
library(glue)
library(here)

site <- "co_pilot"
source(here("01_process_data", "processing_helper.R"))
trials_coded <- read_rds(here(glue("00_prepped_data/{site}/trials_coded.rds")))


```

```{r}
# merge in unique item_ids from corpus (ToDo: add other corpora)
math_items <- load_math_items()
trog_items <- load_grammar_items()
```

```{r}
vocab <- task_data |>
  filter(task_id == "vocab", corpus_trial_type == "test") |> # or assessment_stage=="test_response"
  mutate(item_id = paste0("vocab-",item))

# these items can be answered quite easily in gendered languages
removed_trog_items <- c("33-woman-in-chair", "34-woman-holds-baby", "35-boy-in-tree", "36-girl-before-horse")

trog <- task_data |> 
  filter(task_id == "trog", item!="",
         !answer %in% removed_trog_items) |> # these two items were modified slightly for colorblind-friendliness 
  mutate(answer = ifelse(answer=="74-short-yellow-pencil", "74-short-green-pencil",
                         ifelse(answer=="57-green-chair-red-box", "57-yellow-chair-red-box", answer))) |>
  select(-item_id) |>
  left_join(trog_items |> 
              select(answer, item_id)) # item
```

EF tasks 

```{r}
sds <- process_sds(task_data)
hearts_and_flowers <- process_hearts_and_flowers(task_data, 
                                                 add_corpus_trial_type = TRUE)
mg <- process_mg(task_data)
```

egma needs special processing to identify items

```{r}
egma <- process_egma(task_data)
```


```{r}
# theory of mind is separated by groups of corpus_trial_type +
# has special processing to identify items +
# hostile attribution correctness are recoded
hostile_values <- read_csv(here("01_process_data/metadata/hostile-attribution-coding.csv"))
tom <- task_data |>
  filter(task_id == "theory-of-mind", item!="") |>
  mutate(corpus_trial_type = corpus_trial_type |> str_remove_all("_question")) |>
  mutate(task_id = fct_collapse(corpus_trial_type,
                                "theory-of-mind" = c("false_belief", "reality_check", "reference"),
                                "hostile-attribution" = c("audio", "attribution", "action"),
                                "emotion-reasoning" = "emotion_reasoning")) |>
  group_by(user_id, run_id, task_id, item, corpus_trial_type) |>
  mutate(i = 1:n(), n = n()) |> # sequentially number items
  ungroup() |>
  # item_id = "item [question type]" (+ "[i]" if multiple same type items)
  mutate(item_id = paste(item, str_remove(corpus_trial_type, "_question")),
         item_id = paste(item_id, i)) |>
  # item_id = if_else(n == 1, item_id, paste(item_id, i))) |>
  select(-i, -n) |>
  left_join(hostile_values) |>
  mutate(correct = if_else(str_detect(task_id, "hostile"),
                           value %in% c("purpose", "hostile"),
                           correct)) |>
  select(-value)
```

```{r}

# replace separated out data
task_data_coded <- task_data |>
  filter(!task_id %in% c("egma-math", "same-different-selection", "memory-game", "theory-of-mind", "trog", "vocab", "hearts-and-flowers")) |>
  bind_rows(egma) |> 
  bind_rows(tom) |> 
  bind_rows(trog) |> 
  bind_rows(vocab) |>
  bind_rows(hearts_and_flowers) |>
  bind_rows(mg) |>
  bind_rows(sds) |>
  clean_item_ids() |>
  select(matches("id"), trial_index, corpus_trial_type, 
         chance, correct, rt, response, server_timestamp)

# identify too slow/fast RTs
# TODO: check min/max values + why are some RTs NA
# min_rt <- 0.5
# max_rt <- 50
# task_data_rt <- task_data_coded |>
#   mutate(rt = as.numeric(rt) / 1000, rt_fast = rt < min_rt, rt_slow = rt > max_rt) |>
#   filter(is.na(rt) | rt > 0)

# some plotting to look at rt filters
# ggplot(task_data_rt, aes(x = rt)) +
#   facet_wrap(vars(task_id)) +
#   geom_density() +
#   geom_vline(xintercept = c(min_rt, max_rt), color = "red", linetype = "dashed") +
#   scale_x_log10(labels = scales::comma, breaks = 10 ^ seq(-2, 2)) +
#   labs(x = "Response time (seconds)")
# task_data_rt |> filter(rt_fast) |> count(task_id)
# task_data_rt |> filter(rt_slow) |> count(task_id)

task_data_nested <- task_data_coded |>
  # filter(is.na(rt_fast) | !rt_fast, is.na(rt_slow) | !rt_slow) |> # remove too slow/fast RTs
  # select(-starts_with("rt")) |> # drop all RT columns
  nest(data = everything(), .by = task_id) # nest data by task

write_rds(task_data_nested, here(glue("01_processed_data/{site}/task_data_nested.rds")))
```
