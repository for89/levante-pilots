---
title: "SEM_all_tasks_updated_july2025"
format: html
editor: visual
---
```{r setup}
library(tidyverse)
library(here)
library(glue)
library(lavaan)
library(tidySEM)
library(ggthemes)
library(tidyr)
library(knitr)

source(here("02_score_data","irt_helpers.R"))
source(here("03_summaries", "plotting_helper.R"))
source(here("03_explore_tasks/explore_helper.R"))
```

# Part 1: EFA - 9 core tasks

### load thetas for 9 core tasks (not ROAR, mefs or ha)

```{r}
multigroup <- read_rds(here("02_scoring_outputs","scores",
                             "multigroup_scores.rds"))
colnames(multigroup)
glimpse(multigroup)
unique(multigroup$item_task)

# define tasks for EFA (remove ha)
efa_tasks <- c("hf", "math", "matrix", "mg", "mrot", "sds", "tom", "trog", "vocab")

```

### run ages

```{r}
# create sites
sites <- c("ca_pilot", "co_pilot", "de_pilot")

run_ages <- read_rds(here(glue("01_fetched_data/run_data.rds"))) |>
  select(site, task_id, user_id, run_id, age) |>
  filter(site %in% sites)

ages <- run_ages |>
  group_by(user_id) |>
  summarise(age = mean(age, na.rm=TRUE))
```

### create wide format (one row per participant, one column per task) 

```{r}
# long to wide — one row per participant, one column per task
scores_wide <- multigroup |>
  group_by(user_id, site, item_task) |>
  summarise(metric_value = mean(metric_value, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(names_from = item_task, values_from = metric_value)

# clean names and join age 
scores_wide_mat <- scores_wide |>
  janitor::clean_names() |>
  left_join(ages, by = "user_id")

```

### check n's

```{r}
scores_wide_mat %>%
  select(all_of(efa_tasks)) %>%
  summarise(
    across(everything(),
           ~round(mean(is.na(.)) * 100, 1),
           .names = "missing_pct_{col}")
  )

# check how many tasks each child completed
scores_wide_mat %>%
  mutate(n_tasks = rowSums(!is.na(select(., all_of(efa_tasks))))) %>%
  count(n_tasks) %>%
  arrange(desc(n_tasks))
```

# Part 1: Complete case EFA

### EFA for complete cases - participants with all 9 tasks

```{r}

# select participants with no missing values across the 9 tasks
efa_complete <- scores_wide_mat %>%
  select(all_of(efa_tasks)) %>%
  drop_na() %>%
  mutate(across(everything(), as.numeric))  # Ensure all columns are numeric

# number of complete cases
nrow(efa_complete)

```

### complete case: EFA - complete case sample (psych)

```{r}
library(psych)
psych::KMO(efa_complete) # ha below 0.5 - doesn't share enough variance with the other items - remove.
cortest.bartlett(cor(efa_complete), n = nrow(efa_complete))

# Scree + parallel analysis
fa.parallel(efa_complete, fa = "fa", fm = "ml")

# EFA, 3 fa
efa_result_1 <- fa(efa_complete, nfactors = 3, fm = "ml", rotate = "oblimin")

# View results
print(efa_result_1, cut = 0.2)
```

### complete case (3fa): re-estimate EFA with lavaan (ESEM-style, allowing cross-loadings)

```{r}
# Standardise complete case data for lavaan
efa_complete_z <- efa_complete %>%
  mutate(across(everything(), scale))

# Define EFA model as a string
efa_model_1 <- 'efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab'

# Fit lavaan EFA model
efa_fit_1 <- cfa(efa_model_1,
                 data = efa_complete_z,
                 estimator = "MLR",
                 rotation = "oblimin")

# View results
summary(efa_fit_1, fit.measures = TRUE, standardized = TRUE)
```

# Part 2: estimating using fiml 

# # Note: `psych::fa` provides exploratory loadings via factor analysis (e.g., for initial structure discovery),
# while `lavaan::cfa` here is used in an exploratory SEM (ESEM) framework to estimate the same structure 
# confirmatorily using maximum likelihood with FIML and rotation. This allows direct comparison with later CFA models.

### 5fa

```{r}
# have to standardize to get the model to run in laavan (requires fixed residual variances)
scores_wide_mat_z <- scores_wide_mat %>%
  mutate(across(all_of(efa_tasks), scale))

efa_model_5 <- '
efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 + efa("block1")*F4 + efa("block1")*F5 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_5 <- cfa(efa_model_5,
               data = scores_wide_mat_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_5, fit.measures = TRUE, standardized = TRUE)

# failed - over-fitting

```

### 4fa

```{r}
efa_model_4 <- '
efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 + efa("block1")*F4  =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_4 <- cfa(efa_model_4,
               data = scores_wide_mat_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_4, fit.measures = TRUE, standardized = TRUE)

# failed - over-fitting

```

### 3fa

```{r}

efa_model_3 <- '
efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_3 <- cfa(efa_model_3,
               data = scores_wide_mat_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_3, fit.measures = TRUE, standardized = TRUE)

# get loadings
efa_3_loadings <- parameterEstimates(efa_fit_3, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, est = std.all)

# group by highest loading factor
efa_3_grouped <- efa_3_loadings %>%
  group_by(task) %>%
  slice_max(abs(est), n = 1, with_ties = FALSE) %>%
  arrange(factor, desc(abs(est))) %>%
  ungroup()

efa_3_grouped

efa_3_loadings %>%
  filter(abs(est) > 0.2) %>%
  ggplot(aes(x = task, y = est, fill = factor)) +
  geom_col(position = "dodge") +
  labs(x = "Task", y = "Standardised Loading", fill = "Factor") +
  theme_minimal()


```

#### 2fa

```{r}

efa_model_2 <- '
efa("block1")*F1 + efa("block1")*F2 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_2 <- cfa(efa_model_2,
               data = scores_wide_mat_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_2, fit.measures = TRUE, standardized = TRUE)

# get loadings
efa_2_loadings <- parameterEstimates(efa_fit_2, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, est = std.all)

# group by highest loading factor
efa_2_grouped <- efa_2_loadings %>%
  group_by(task) %>%
  slice_max(abs(est), n = 1, with_ties = FALSE) %>%
  arrange(factor, desc(abs(est))) %>%
  ungroup()

efa_2_grouped

efa_2_loadings %>%
  filter(abs(est) > 0.2) %>%
  ggplot(aes(x = task, y = est, fill = factor)) +
  geom_col(position = "dodge") +
  labs(x = "Task", y = "Standardised Loading", fill = "Factor") +
  theme_minimal()

```

### 1 fa

```{r}

efa_model_1 <- '
efa("block1")*F1 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_1 <- cfa(efa_model_1,
               data = scores_wide_mat_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_1, fit.measures = TRUE, standardized = TRUE)

# get loadings
efa_1_loadings <- parameterEstimates(efa_fit_1, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, est = std.all)

# group by highest loading factor
efa_1_grouped <- efa_1_loadings %>%
  group_by(task) %>%
  slice_max(abs(est), n = 1, with_ties = FALSE) %>%
  arrange(factor, desc(abs(est))) %>%
  ungroup()

efa_1_grouped

efa_1_loadings %>%
  filter(abs(est) > 0.2) %>%
  ggplot(aes(x = task, y = est, fill = factor)) +
  geom_col(position = "dodge") +
  labs(x = "Task", y = "Standardised Loading", fill = "Factor") +
  theme_minimal()

```

### compare fit indices - EFA

```{r}

# compare 1-factor vs 2-factor models
anova(fit_1f, fit_2f)

# compare 2-factor vs 3-factor models
anova(fit_2f, fit_3f) # sig improvement (Δχ²(3) = 84.94, p < .001) supports 3-factor model over 2-factor

model_comparison_efa <- tibble(
  model = c("1-factor", "2-factor", "3-factor"),
  chisq = c(fitMeasures(efa_fit_1, "chisq"),
            fitMeasures(efa_fit_2, "chisq"),
            fitMeasures(efa_fit_3, "chisq")),
  df = c(fitMeasures(efa_fit_1, "df"),
         fitMeasures(efa_fit_2, "df"),
         fitMeasures(efa_fit_3, "df")),
  cfi = c(fitMeasures(efa_fit_1, "cfi"),
          fitMeasures(efa_fit_2, "cfi"),
          fitMeasures(efa_fit_3, "cfi")),
  tli = c(fitMeasures(efa_fit_1, "tli"),
          fitMeasures(efa_fit_2, "tli"),
          fitMeasures(efa_fit_3, "tli")),
  rmsea = c(fitMeasures(efa_fit_1, "rmsea"),
            fitMeasures(efa_fit_2, "rmsea"),
            fitMeasures(efa_fit_3, "rmsea")),
  bic = c(fitMeasures(efa_fit_1, "bic"),
          fitMeasures(efa_fit_2, "bic"),
          fitMeasures(efa_fit_3, "bic"))
)

model_comparison_efa

# 3 fa model is the best fitting.

```

### CFA for 3 fa model  

```{r}

model_3f <- '
factor1 =~ hf + mg + math 
factor2 =~ tom + matrix + mrot 
factor3 =~ trog + vocab + sds

# Add age regressions
factor1 ~ age
factor2 ~ age
factor3 ~ age
'
fit_3f <- cfa(model_3f, data = scores_wide_mat_z,
              std.lv = TRUE, missing = "fiml",
              bounds = list(lower = 0.001)) # included to avoid heywood cases

summary(fit_3f, fit.measures = TRUE, standardize = TRUE)
```

### path diagram

```{r}
layout <- matrix(nrow = 5, ncol = 11, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "tom", "matrix", "mrot", NA, "trog", "vocab", "sds",
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  "factor1", NA, NA, NA, "factor2", NA, NA, NA, "factor3", NA, NA,
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  NA, NA, NA, NA, "age", NA, NA, NA, NA, NA, NA
))

graph_sem(fit_3f, layout = layout, text_size = 2.5)

```

### CFA for 2 fa model  

```{r}
model_2f <- '
factor1 =~ hf + mg + math 
factor2 =~ trog + vocab + tom + sds + matrix + mrot

# Add age regressions
factor1 ~ age
factor2 ~ age
'

fit_2f <- cfa(model_2f, data = scores_wide_mat_z,
              std.lv = TRUE, missing = "fiml",
              bounds = list(lower = 0.001)) # included to avoid heywood cases

summary(fit_2f, fit.measures = TRUE, standardize = TRUE)
```

### path diagram

```{r}
layout <- matrix(nrow = 5, ncol = 10, byrow = TRUE, data = c(
  "hf",    "mg",    "math",   NA,    "sds", "tom",  "matrix", "mrot",  "trog", "vocab",
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  "factor1", NA,    NA,       NA,    NA,  "factor2", NA,    NA,      NA,     NA,
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  NA,      NA,      NA,       NA,  "age", NA,     NA,       NA,      NA,     NA
))

graph_sem(fit_2f, layout = layout, text_size = 2.5)

```

### CFA for 1 fa

```{r}

model_1f <- '
factor1 =~ mg + math + sds + tom + matrix + mrot + trog + vocab + hf

# Add age regressions
factor1 ~ age
'

fit_1f <- cfa(model_1f, data = scores_wide_mat_z,
              std.lv = TRUE, missing = "fiml",
              bounds = list(lower = 0.001)) # included to avoid heywood cases

summary(fit_1f, fit.measures = TRUE, standardize = TRUE)
```

### path diagram

```{r}
layout <- matrix(nrow = 5, ncol = 10, byrow = TRUE, data = c(
  "hf",    "mg",    "math",   "sds", "tom",  "matrix", "mrot",  "trog", "vocab", NA,
  NA,      NA,      NA,       NA,    NA,     NA,       NA,      NA,     NA,     NA,
  "factor1", NA,    NA,       NA,    NA,     NA,       NA,      NA,     NA,     NA,
  NA,      NA,      NA,       NA,    NA,     NA,       NA,      NA,     NA,     NA,
  NA,      NA,      NA,       NA,    "age",  NA,       NA,      NA,     NA,     NA
))


graph_sem(fit_1f, layout = layout, text_size = 2.5)

# 3 factor model is unstable; revert to 2 factor model.

```
### model comparison - CFA models

```{r}
model_comparison_cfa <- tibble(
  model = c("model_3f", "model_2f", "model_1f"),
  chisq = c(fitMeasures(fit_3f, "chisq"),
            fitMeasures(fit_2f, "chisq"),
            fitMeasures(fit_1f, "chisq")),
  df = c(fitMeasures(fit_3f, "df"),
         fitMeasures(fit_2f, "df"),
         fitMeasures(fit_1f, "df")),
  cfi = c(fitMeasures(fit_3f, "cfi"),
          fitMeasures(fit_2f, "cfi"),
          fitMeasures(fit_1f, "cfi")),
  tli = c(fitMeasures(fit_3f, "tli"),
          fitMeasures(fit_2f, "tli"),
          fitMeasures(fit_1f, "tli")),
  rmsea = c(fitMeasures(fit_3f, "rmsea"),
            fitMeasures(fit_2f, "rmsea"),
            fitMeasures(fit_1f, "rmsea")),
  bic = c(fitMeasures(fit_3f, "bic"),
          fitMeasures(fit_2f, "bic"),
          fitMeasures(fit_1f, "bic"))
)

model_comparison_cfa

# 3 fa best performing
```

## Measurement invariance

```{r}
# 3 fa model with age removed
model_3f_mi <- '
factor1 =~ hf + mg + math 
factor2 =~ tom + matrix + mrot 
factor3 =~ trog + vocab + sds
'
library(semTools)
mi_3f <- measurementInvariance(
  model = model_3f_mi,
  data = scores_wide_mat_z,
  group = "site",
  estimator = "MLR"
)

# partial (stop at metric)
mi_3f_partial <- measurementInvariance(
  model = model_3f_mi,
  data = scores_wide_mat_z,
  group = "site",
  estimator = "MLR",
  strict = FALSE
)

# look at fit
summary(mi_3f_partial$fit.configural, fit.measures = TRUE)
summary(mi_3f_partial$fit.metric, fit.measures = TRUE)

anova(mi_3f_partial$fit.configural, mi_3f_partial$fit.metric)

# compare
fit_config <- mi_3f_partial$fit.configural
fit_metric <- mi_3f_partial$fit.metric

fitMeasures(fit_config, c("cfi", "rmsea", "aic", "bic"))
fitMeasures(fit_metric, c("cfi", "rmsea", "aic", "bic"))

anova(fit_config, fit_metric)


```

## By site - 3 factor model

### Columbia

```{r}
# filter data - co_pilot
scores_co <- scores_wide_mat_z %>%
  filter(site == "co_pilot")

# define model 
model_3f_co <- '
factor1 =~ hf + mg + math
factor2 =~ tom + matrix + mrot
factor3 =~ trog + vocab + sds

factor1 ~ age
factor2 ~ age
factor3 ~ age
'

# fit model
fit_3f_co <- cfa(model_3f_co,
                 data = scores_co,
                 std.lv = TRUE,
                 missing = "fiml",  
                 bounds = list(lower = 0.001))  # avoid heywood cases

summary(fit_3f_co, fit.measures = TRUE, standardized = TRUE)

layout <- matrix(nrow = 5, ncol = 11, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "tom", "matrix", "mrot", NA, "trog", "vocab", "sds",
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  "factor1", NA, NA, NA, "factor2", NA, NA, NA, "factor3", NA, NA,
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  NA, NA, NA, NA, "age", NA, NA, NA, NA, NA, NA
))

graph_sem(fit_3f_co, layout = layout, text_size = 2.5)

# Note: “370 cases were deleted due to missing values in exogenous variable(s), while fixed.x = TRUE.” - check why age is missing.

```

### Germany

```{r}
scores_de <- scores_wide_mat_z %>%
  filter(site == "de_pilot")

# define model 
model_3f_de <- '
factor1 =~ hf + mg + math
factor2 =~ tom + matrix + mrot
factor3 =~ trog + vocab + sds

factor1 ~ age
factor2 ~ age
factor3 ~ age
'

# fit model
fit_3f_de <- cfa(model_3f_de,
                 data = scores_de,
                 std.lv = TRUE,
                 missing = "fiml", 
                 bounds = list(lower = 0.001))  

summary(fit_3f_de, fit.measures = TRUE, standardized = TRUE)

layout <- matrix(nrow = 5, ncol = 11, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "tom", "matrix", "mrot", NA, "trog", "vocab", "sds",
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  "factor1", NA, NA, NA, "factor2", NA, NA, NA, "factor3", NA, NA,
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  NA, NA, NA, NA, "age", NA, NA, NA, NA, NA, NA
))

graph_sem(fit_3f_de, layout = layout, text_size = 2.5)


```

### Canada

```{r}
scores_ca <- scores_wide_mat_z %>%
  filter(site == "ca_pilot")

# define model 
model_3f_ca <- '
factor1 =~ hf + mg + math
factor2 =~ tom + matrix + mrot
factor3 =~ trog + vocab + sds

factor1 ~ age
factor2 ~ age
factor3 ~ age
'

# fit model
fit_3f_ca <- cfa(model_3f_ca,
                 data = scores_ca,
                 std.lv = TRUE,
                 missing = "fiml", 
                 bounds = list(lower = 0.001))  

summary(fit_3f_ca, fit.measures = TRUE, standardized = TRUE)

layout <- matrix(nrow = 5, ncol = 11, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "tom", "matrix", "mrot", NA, "trog", "vocab", "sds",
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  "factor1", NA, NA, NA, "factor2", NA, NA, NA, "factor3", NA, NA,
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  NA, NA, NA, NA, "age", NA, NA, NA, NA, NA, NA
))

graph_sem(fit_3f_ca, layout = layout, text_size = 2.5)

```

# IMV to Compare 1-, 2-, and 3-Factor Models

### define models - 1 factor

```{r}
# Install Lijin's package
install.packages("devtools")
devtools::install_github("zhanglj37/imv4sem")
library(imv4sem)
```


```{r}
# reminder of model names - model_1f, model_2f, model_3f
### check structures - has to be numeric.

scores_wide_mat_z %>%
  select(all_of(efa_tasks)) %>%
  summarise_all(class)

scores_wide_mat_z <- scores_wide_mat_z %>%
  mutate(across(all_of(efa_tasks), ~as.numeric(as.character(.))))
```

### compare baseline model

```{r}
# Model 2 vs baseline
imv2 <- imvsem(model1 = model_2f,
               data = scores_wide_mat_z,
               vary = efa_tasks,
               nfold = 5)
plot4imv(imv2)

```

### compare 2 fa v 1 fa

```{r}
imv_2vs1 <- imvsem(model1 = model_2f,
                   model2 = model_1f,
                   data = scores_wide_mat_z,
                   vary = efa_tasks,
                   nfold = 5)
plot4imv(imv_2vs1)

```

### compare 3 fa v 2 fa

```{r}
imv_3vs2 <- imvsem(model1 = model_3f,
                   model2 = model_2f,
                   data = scores_wide_mat_z,
                   vary = efa_tasks,
                   nfold = 5)
plot4imv(imv_3vs2)

```

# END. 







































# OLD

# COMPLETE CASE (removed)

### complete case: print loadings

```{r}
loadings_above_0.2 <- parameterEstimates(efa_fit_1, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, loading = std.all) %>%
  filter(abs(loading) > 0.2) %>%
  arrange(factor, desc(abs(loading)))

print(loadings_above_0.2)

```

### complete case: compare to 2 fa strucutre, complete case

```{r}
# EFA, 2 fa
efa_result_2 <- fa(efa_complete, nfactors = 2, fm = "ml", rotate = "oblimin")

# View results
print(efa_result_2, cut = 0.2)

# Define EFA model as a string
efa_model_2 <- 'efa("block1")*F1 + efa("block1")*F2 =~ 
  ha + hf + math + matrix + mg + mrot + sds + tom + trog + vocab'

# lavaan EFA model
efa_fit_2 <- cfa(efa_model_2,
                 data = efa_complete_z,
                 estimator = "MLR",
                 rotation = "oblimin")

summary(efa_fit_2, fit.measures = TRUE, standardized = TRUE)

```

### complete case: compare 2 fa and 3 fa - complete case 

```{r}

compare_cc <- tibble::tibble(
  Model = c("3-factor", "2-factor"),
  TLI = c(efa_result_1$TLI, efa_result_2$TLI),
  RMSEA = c(efa_result_1$RMSEA[1], efa_result_2$RMSEA[1]),
  BIC = c(efa_result_1$BIC, efa_result_2$BIC),
  RMSR = c(efa_result_1$rms, efa_result_2$rms),
  Proportion_Var = c(sum(efa_result_1$Vaccounted[2, ]),
                     sum(efa_result_2$Vaccounted[2, ]))
)

print(compare_cc)

# 3 fa better overall

```

### complete case: compare loadings across 2 and 3 fa structures

```{r}
get_loadings <- function(fit, threshold = 0.2) {
  parameterEstimates(fit, standardized = TRUE) %>%
    filter(op == "=~") %>%
    select(factor = lhs, task = rhs, loading = std.all) %>%
    filter(abs(loading) > threshold) %>%
    arrange(task, desc(abs(loading)))
}

loadings_3f <- get_loadings(efa_fit_1)
loadings_2f <- get_loadings(efa_fit_2)

print(loadings_3f)
print(loadings_2f)

```


```