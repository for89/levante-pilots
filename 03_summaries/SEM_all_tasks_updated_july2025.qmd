---
title: "SEM_all_tasks_updated_july2025"
format: html
editor: visual
---

```{r setup}
library(tidyverse)
library(here)
library(glue)
library(lavaan)
library(tidySEM)
library(ggthemes)
library(tidyr)
library(knitr)

source(here("02_score_data","irt_helpers.R"))
source(here("03_summaries", "plotting_helper.R"))
source(here("03_explore_tasks/explore_helper.R"))
```

# Part 1: EFA - 9 core tasks

### load thetas for 9 core tasks (not ROAR, mefs or ha)

```{r}
scores <- read_rds(here("02_scoring_outputs","scores",
                             "scores_combined.rds"))
colnames(scores)
glimpse(scores)
unique(scores$item_task)

# define tasks for EFA (remove ha)
core_tasks <- c("hf", "math", "matrix", "mg", "mrot", "sds", "tom", "trog", "vocab")


```

check completeness

```{r}

# check n's
scores %>%
  filter(item_task %in% core_tasks,
         metric_type == "ability") %>%
  group_by(item_task) %>%
  summarise(
    n_participants = n_distinct(user_id),  # unique participants per task
    .groups = "drop"
  )

# Count how many tasks each participant completed
scores_wide <- scores %>%
  filter(item_task %in% core_tasks,
         metric_type == "ability") %>%
  group_by(user_id, item_task) %>%
  summarise(score = mean(metric_value, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = item_task, values_from = score)

scores_wide %>%
  mutate(
    n_completed = rowSums(!is.na(select(., all_of(core_tasks))))
  ) %>%
  count(n_completed) %>%
  arrange(desc(n_completed))

```

### create wide format (one row per participant, one column per task)

```{r}

# keep only core tasks 
scores_wide <- scores %>%
  filter(item_task %in% core_tasks,
         metric_type == "ability") %>%  c
  group_by(user_id, item_task) %>%
  summarise(score = mean(metric_value, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = item_task, values_from = score)

# remove rows with all missing task scores
scores_wide <- scores_wide %>%
  filter(rowSums(is.na(select(., all_of(core_tasks)))) < length(core_tasks))

# check missingness per task
colMeans(is.na(scores_wide[core_tasks])) * 100

```


# Part 1: Complete case EFA

### EFA for complete cases - participants with all 9 tasks

```{r}

# select participants with no missing values across the 9 tasks
efa_complete <- scores_wide %>%
  select(all_of(core_tasks)) %>%
  drop_na() %>%
  mutate(across(everything(), as.numeric))  # Ensure all columns are numeric

# number of complete cases
nrow(efa_complete)

```

### complete case: EFA - complete case sample (psych)

```{r}
library(psych)
psych::KMO(efa_complete) # ha below 0.5 - doesn't share enough variance with the other items - remove.
cortest.bartlett(cor(efa_complete), n = nrow(efa_complete))

# Scree + parallel analysis
fa.parallel(efa_complete, fa = "fa", fm = "ml")

# EFA, 3 fa
efa_result_1 <- fa(efa_complete, nfactors = 3, fm = "ml", rotate = "oblimin")

# View results
print(efa_result_1, cut = 0.2)
```

### complete case (3fa): re-estimate EFA with lavaan (ESEM-style, allowing cross-loadings)

```{r}
# Standardise complete case data for lavaan
efa_complete_z <- efa_complete %>%
  mutate(across(everything(), scale))

# Define EFA model as a string
efa_model_1 <- 'efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab'

# Fit lavaan EFA model
efa_fit_1 <- cfa(efa_model_1,
                 data = efa_complete_z,
                 estimator = "MLR",
                 rotation = "oblimin")

# View results
summary(efa_fit_1, fit.measures = TRUE, standardized = TRUE)
```

# Part 2: estimating using fiml

# Note: `psych::fa` provides exploratory loadings via factor analysis (e.g., for initial structure discovery), while `lavaan::cfa` here \# is used in an exploratory SEM (ESEM) framework to estimate the same structure confirmatorily, using maximum likelihood with FIML and

# rotation. This allows direct comparison with later CFA models.

### standarise data

```{r}

# have to standardize to get the model to run in laavan (requires fixed residual variances)
# pick one age per user (earliest record)
ages <- scores %>%
  filter(item_task %in% core_tasks, metric_type == "ability") %>%
  group_by(user_id) %>%
  arrange(time_started) %>%
  summarise(age = first(na.omit(age)), .groups = "drop")

scores_wide_z <- scores_wide %>%
  left_join(ages, by = "user_id") %>%
  mutate(
    age = as.numeric(age),                         # keep age numeric, unscaled
    across(all_of(core_tasks), ~ as.numeric(scale(.)))
  )

```

### 5fa

```{r}

efa_model_5 <- '
efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 + efa("block1")*F4 + efa("block1")*F5 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_5 <- cfa(efa_model_5,
               data = scores_wide_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_5, fit.measures = TRUE, standardized = TRUE)

# This model runs but many heywood cases (negative variance), NA fit indices, small/unstable loadings, high factor intercorrelations
# Indicating too many factors

```

### 4fa

```{r}
efa_model_4 <- '
efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 + efa("block1")*F4  =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_4 <- cfa(efa_model_4,
               data = scores_wide_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_4, fit.measures = TRUE, standardized = TRUE)

# failed - over-fitting

```

### 3fa

```{r}

efa_model_3 <- '
efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_3 <- cfa(efa_model_3,
               data = scores_wide_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_3, fit.measures = TRUE, standardized = TRUE)

# also failed - over-fitting

# get loadings
efa_3_loadings <- parameterEstimates(efa_fit_3, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, est = std.all)

# group by highest loading factor
efa_3_grouped <- efa_3_loadings %>%
  group_by(task) %>%
  slice_max(abs(est), n = 1, with_ties = FALSE) %>%
  arrange(factor, desc(abs(est))) %>%
  ungroup()

efa_3_grouped

efa_3_loadings %>%
  filter(abs(est) > 0.2) %>%
  ggplot(aes(x = task, y = est, fill = factor)) +
  geom_col(position = "dodge") +
  labs(x = "Task", y = "Standardised Loading", fill = "Factor") +
  theme_minimal()


```

#### 2fa

```{r}

efa_model_2 <- '
efa("block1")*F1 + efa("block1")*F2 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_2 <- cfa(efa_model_2,
               data = scores_wide_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_2, fit.measures = TRUE, standardized = TRUE)

# get loadings
efa_2_loadings <- parameterEstimates(efa_fit_2, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, est = std.all)

# group by highest loading factor
efa_2_grouped <- efa_2_loadings %>%
  group_by(task) %>%
  slice_max(abs(est), n = 1, with_ties = FALSE) %>%
  arrange(factor, desc(abs(est))) %>%
  ungroup()

efa_2_grouped

efa_2_loadings %>%
  filter(abs(est) > 0.2) %>%
  ggplot(aes(x = task, y = est, fill = factor)) +
  geom_col(position = "dodge") +
  labs(x = "Task", y = "Standardised Loading", fill = "Factor") +
  theme_minimal()

```

### 1 fa

```{r}

efa_model_1 <- '
efa("block1")*F1 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'
efa_fit_1 <- cfa(efa_model_1,
               data = scores_wide_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_1, fit.measures = TRUE, standardized = TRUE)

# get loadings
efa_1_loadings <- parameterEstimates(efa_fit_1, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, est = std.all)

# group by highest loading factor
efa_1_grouped <- efa_1_loadings %>%
  group_by(task) %>%
  slice_max(abs(est), n = 1, with_ties = FALSE) %>%
  arrange(factor, desc(abs(est))) %>%
  ungroup()

efa_1_grouped

efa_1_loadings %>%
  filter(abs(est) > 0.2) %>%
  ggplot(aes(x = task, y = est, fill = factor)) +
  geom_col(position = "dodge") +
  labs(x = "Task", y = "Standardised Loading", fill = "Factor") +
  theme_minimal()

```

### compare fit indices - EFA

```{r}

library(tibble)

# 1) Run on its own line
anova(efa_fit_1, efa_fit_2)

# 2) Then build the comparison table (separate statement)
model_comparison_efa <- tibble(
  model = c("1-factor", "2-factor"),
  chisq = c(fitMeasures(efa_fit_1, "chisq"),
            fitMeasures(efa_fit_2, "chisq")),
  df    = c(fitMeasures(efa_fit_1, "df"),
            fitMeasures(efa_fit_2, "df")),
  cfi   = c(fitMeasures(efa_fit_1, "cfi.robust"),
            fitMeasures(efa_fit_2, "cfi.robust")),
  tli   = c(fitMeasures(efa_fit_1, "tli.robust"),
            fitMeasures(efa_fit_2, "tli.robust")),
  rmsea = c(fitMeasures(efa_fit_1, "rmsea.robust"),
            fitMeasures(efa_fit_2, "rmsea.robust")),
  bic   = c(fitMeasures(efa_fit_1, "bic"),
            fitMeasures(efa_fit_2, "bic"))
)

model_comparison_efa

```

### CFA for 3 fa model - stopping here - 12.08.2025

```{r}

model_2f <- '
factor1 =~ tom + mrot 
factor2 =~ hf + mg + math + matrix +trog + vocab + sds

# add age regressions
factor1 ~ age
factor2 ~ age
'

colnames(scores_wide_z)

fit_2f <- cfa(model_2f, data = scores_wide_z,
              std.lv = TRUE, missing = "fiml",
              fixed.x = FALSE,  # so that it doesn't drop those who are missing age
              bounds = list(lower = 0.001)) # included to avoid heywood cases

summary(fit_2f, fit.measures = TRUE, standardize = TRUE)
```

### path diagram

```{r}
layout <- matrix(nrow = 5, ncol = 11, byrow = TRUE, data = c(
  "tom", "mrot", NA, NA, "hf", "mg", "math", "matrix", "trog", "vocab", "sds", 
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  "factor1", NA, NA, NA, NA, "factor2", NA, NA, NA, NA, NA, 
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  NA, NA, NA, NA, "age", NA, NA, NA, NA, NA, NA
))

graph_sem(fit_2f, layout = layout, text_size = 2.5)

```

### CFA for 1 fa

```{r}
model_1f <- '
factor1 =~ mg + math + sds + tom + matrix + mrot + trog + vocab + hf

# Add age regressions
factor1 ~ age
'

fit_1f <- cfa(model_1f, data = scores_wide_z,
              std.lv = TRUE, missing = "fiml",
               fixed.x = FALSE,
              bounds = list(lower = 0.001)) # included to avoid heywood cases

summary(fit_1f, fit.measures = TRUE, standardize = TRUE)
```

### path diagram

```{r}
layout <- matrix(nrow = 5, ncol = 10, byrow = TRUE, data = c(
  "hf",    "mg",    "math",   "sds", "tom",  "matrix", "mrot",  "trog", "vocab", NA,
  NA,      NA,      NA,       NA,    NA,     NA,       NA,      NA,     NA,     NA,
  "factor1", NA,    NA,       NA,    NA,     NA,       NA,      NA,     NA,     NA,
  NA,      NA,      NA,       NA,    NA,     NA,       NA,      NA,     NA,     NA,
  NA,      NA,      NA,       NA,    "age",  NA,       NA,      NA,     NA,     NA
))

graph_sem(fit_1f, layout = layout, text_size = 2.5)

```

### model comparison - CFA models

```{r}

# Likelihood-ratio (robust Satorra–Bentler) test
lavTestLRT(fit_1f, fit_2f)

# Comparison table: 1 vs 2 factors
model_comparison_cfa <- tibble::tibble(
  model = c("1-factor", "2-factor"),
  chisq = c(fitMeasures(fit_1f, "chisq"),
            fitMeasures(fit_2f, "chisq")),
  df    = c(fitMeasures(fit_1f, "df"),
            fitMeasures(fit_2f, "df")),
  cfi   = c(fitMeasures(fit_1f, "cfi"),
            fitMeasures(fit_2f, "cfi")),
  tli   = c(fitMeasures(fit_1f, "tli"),
            fitMeasures(fit_2f, "tli")),
  rmsea = c(fitMeasures(fit_1f, "rmsea"),
            fitMeasures(fit_2f, "rmsea")),
  bic   = c(fitMeasures(fit_1f, "bic"),
            fitMeasures(fit_2f, "bic"))
)
model_comparison_cfa

```

### OLD, needs updating


## Measurement invariance (not working at the mo)

```{r}
# 3 fa model with age removed
model_3f_mi <- '
factor1 =~ hf + mg + math 
factor2 =~ tom + matrix + mrot 
factor3 =~ trog + vocab + sds
'

fit_configural <- cfa(
  model_3f_mi,
  data = scores_wide_mat_z,
  group = "site",
  missing = "fiml",
  std.lv = TRUE
)

lavInspect(fit_configural, "coverage") # shows proportion of pairwise non-missing cases for each variable pair within each site
# note: columbia is a problem: Near-zero coverage for mrot, sds, and tom.

# not working - too much missingness across 9 tasks

# check group sizes
scores_wide_mat_z %>%
  group_by(site) %>%
  summarise(
    n_total = n(),
    n_complete = sum(complete.cases(across(c(hf, mg, math, tom, matrix, mrot, trog, vocab, sds))))
  )

# Germany only because it has most data across 9 tasks
scores_de <- scores_wide_mat_z %>%
  filter(site == "de_pilot")

fit_3f_mi_de <- cfa(model_3f_mi, data = scores_de, std.lv = TRUE, missing = "fiml")
summary(fit_3f_mi_de, fit.measures = TRUE, standardized = TRUE)

# Examining Columbia more closely
scores_wide_mat_z %>%
  filter(site == "co_pilot") %>%
  summarise(across(c(hf, mg, math, tom, matrix, mrot, trog, vocab, sds),
                   ~ sum(!is.na(.))))
lavInspect(fit_configural, "coverage")$co_pilot
coverage <- lavInspect(fit_configural, "coverage")$co_pilot
sum(coverage < 0.10)

```

## By site - 3 factor model

### Columbia

```{r}
# filter data - co_pilot
scores_co <- scores_wide_mat_z %>%
  filter(site == "co_pilot")

# define model 
model_3f_co <- '
factor1 =~ hf + mg + math
factor2 =~ tom + matrix + mrot
factor3 =~ trog + vocab + sds

factor1 ~ age
factor2 ~ age
factor3 ~ age
'

# fit model
fit_3f_co <- cfa(model_3f_co,
                 data = scores_co,
                 std.lv = TRUE,
                 fixed.x = FALSE,
                 missing = "fiml",  
                 bounds = list(lower = 0.001))  # avoid heywood cases

summary(fit_3f_co, fit.measures = TRUE, standardized = TRUE)

layout <- matrix(nrow = 5, ncol = 11, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "tom", "matrix", "mrot", NA, "trog", "vocab", "sds",
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  "factor1", NA, NA, NA, "factor2", NA, NA, NA, "factor3", NA, NA,
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  NA, NA, NA, NA, "age", NA, NA, NA, NA, NA, NA
))

graph_sem(fit_3f_co, layout = layout, text_size = 2.5)

# Note: “370 cases were deleted due to missing values in exogenous variable(s), while fixed.x = TRUE.” - check why age is missing.

```

### Germany

```{r}
scores_de <- scores_wide_mat_z %>%
  filter(site == "de_pilot")

# define model 
model_3f_de <- '
factor1 =~ hf + mg + math
factor2 =~ tom + matrix + mrot
factor3 =~ trog + vocab + sds

factor1 ~ age
factor2 ~ age
factor3 ~ age
'

# fit model
fit_3f_de <- cfa(model_3f_de,
                 data = scores_de,
                 fixed.x = FALSE,
                 std.lv = TRUE,
                 missing = "fiml", 
                 bounds = list(lower = 0.001))  

summary(fit_3f_de, fit.measures = TRUE, standardized = TRUE)

layout <- matrix(nrow = 5, ncol = 11, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "tom", "matrix", "mrot", NA, "trog", "vocab", "sds",
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  "factor1", NA, NA, NA, "factor2", NA, NA, NA, "factor3", NA, NA,
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  NA, NA, NA, NA, "age", NA, NA, NA, NA, NA, NA
))

graph_sem(fit_3f_de, layout = layout, text_size = 2.5)


```

### Canada

```{r}
scores_ca <- scores_wide_mat_z %>%
  filter(site == "ca_pilot")

# define model 
model_3f_ca <- '
factor1 =~ hf + mg + math
factor2 =~ tom + matrix + mrot
factor3 =~ trog + vocab + sds

factor1 ~ age
factor2 ~ age
factor3 ~ age
'

# fit model
fit_3f_ca <- cfa(model_3f_ca,
                 data = scores_ca,
                 fixed.x = FALSE,
                 std.lv = TRUE,
                 missing = "fiml", 
                 bounds = list(lower = 0.001))  

summary(fit_3f_ca, fit.measures = TRUE, standardized = TRUE)

layout <- matrix(nrow = 5, ncol = 11, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "tom", "matrix", "mrot", NA, "trog", "vocab", "sds",
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  "factor1", NA, NA, NA, "factor2", NA, NA, NA, "factor3", NA, NA,
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  NA, NA, NA, NA, "age", NA, NA, NA, NA, NA, NA
))

graph_sem(fit_3f_ca, layout = layout, text_size = 2.5)

```

# Using cvsem()

```{r}
install.packages("cvsem")
library(cvsem)
ls("package:cvsem")


# prep models
efa_models <- list(
  efa_1f = 'efa("block1")*F1 =~ hf + mg + math + matrix + mrot + sds + tom + trog + vocab',
  efa_2f = 'efa("block1")*F1 + efa("block1")*F2 =~ hf + mg + math + matrix + mrot + sds + tom + trog + vocab',
  efa_3f = 'efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 =~ hf + mg + math + matrix + mrot + sds + tom + trog + vocab',
  efa_4f = 'efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 + efa("block1")*F4 =~ hf + mg + math + matrix + mrot + sds + tom + trog + vocab',
  efa_5f = 'efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 + efa("block1")*F4 + efa("block1")*F5 =~ hf + mg + math + matrix + mrot + sds + tom + trog + vocab'
)

# Models <- cvgather(
#  model.syntax = efa_models,
#  data = scores_wide_mat_z,
#  estimator = "MLR",
#  missing = "fiml",
#  rotation = "oblimin",
#  model.name = names(efa_models)
# )

Models <- do.call(cvgather, efa_models)

cv_results <- cvsem(
  Models = Models,
  data = scores_wide_mat_z,
  k = 10,
  lavaanFunction = "cfa",
  echo = TRUE
)

summary(cv_results)
plot(cv_results)

# debug
sum(is.na(scores_wide_mat_z))
colSums(is.na(scores_wide_mat_z))
names(scores_wide_mat_z)
str(scores_wide_mat_z)




```

### this is not working (getting this error: Error in FUN(X\[\[i\]\], ...) : object 'unique_names' not found), trying a different way

```{r}

library(cvsem)
# define list of named model strings
efa_models <- setNames(
  list(
    efa_model_1,
    efa_model_2,
    efa_model_3,
    efa_model_4,
    efa_model_5
  ),
  nm = c("efa_1f", "efa_2f", "efa_3f", "efa_4f", "efa_5f")
)

# gather into cvsem-compatible structure
Models <- cvgather(
  model.syntax = efa_models,
  data = scores_wide_mat_z,
  estimator = "MLR",
  missing = "fiml",
  rotation = "oblimin"
)

cv_results <- cvsem(
  Models = Models,
  data = scores_wide_mat_z,
  folds = 10,
  parallel = TRUE
)

# still not working

```

# OLD

# COMPLETE CASE (removed)

### complete case: print loadings

```{r}
loadings_above_0.2 <- parameterEstimates(efa_fit_1, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, loading = std.all) %>%
  filter(abs(loading) > 0.2) %>%
  arrange(factor, desc(abs(loading)))

print(loadings_above_0.2)

```

### complete case: compare to 2 fa strucutre, complete case

```{r}
# EFA, 2 fa
efa_result_2 <- fa(efa_complete, nfactors = 2, fm = "ml", rotate = "oblimin")

# View results
print(efa_result_2, cut = 0.2)

# Define EFA model as a string
efa_model_2 <- 'efa("block1")*F1 + efa("block1")*F2 =~ 
  ha + hf + math + matrix + mg + mrot + sds + tom + trog + vocab'

# lavaan EFA model
efa_fit_2 <- cfa(efa_model_2,
                 data = efa_complete_z,
                 estimator = "MLR",
                 rotation = "oblimin")

summary(efa_fit_2, fit.measures = TRUE, standardized = TRUE)

```

### complete case: compare 2 fa and 3 fa - complete case

```{r}

compare_cc <- tibble::tibble(
  Model = c("3-factor", "2-factor"),
  TLI = c(efa_result_1$TLI, efa_result_2$TLI),
  RMSEA = c(efa_result_1$RMSEA[1], efa_result_2$RMSEA[1]),
  BIC = c(efa_result_1$BIC, efa_result_2$BIC),
  RMSR = c(efa_result_1$rms, efa_result_2$rms),
  Proportion_Var = c(sum(efa_result_1$Vaccounted[2, ]),
                     sum(efa_result_2$Vaccounted[2, ]))
)

print(compare_cc)

# 3 fa better overall

```

### complete case: compare loadings across 2 and 3 fa structures

```{r}
get_loadings <- function(fit, threshold = 0.2) {
  parameterEstimates(fit, standardized = TRUE) %>%
    filter(op == "=~") %>%
    select(factor = lhs, task = rhs, loading = std.all) %>%
    filter(abs(loading) > threshold) %>%
    arrange(task, desc(abs(loading)))
}

loadings_3f <- get_loadings(efa_fit_1)
loadings_2f <- get_loadings(efa_fit_2)

print(loadings_3f)
print(loadings_2f)

```

\`\`\`
