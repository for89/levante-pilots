---
title: "SEM_all_tasks_updated_july2025"
format: html
editor: visual
---
```{r setup}
library(tidyverse)
library(here)
library(glue)
library(lavaan)
library(tidySEM)
library(ggthemes)
library(tidyr)
library(knitr)

source(here("02_score_data","irt_helpers.R"))
source(here("03_summaries", "plotting_helper.R"))
source(here("03_explore_tasks/explore_helper.R"))
```

# Part 1: EFA - 9 core tasks

### load thetas for 9 core tasks (not ROAR, mefs or ha)

```{r}
multigroup <- read_rds(here("02_scoring_outputs","scores",
                             "multigroup_scores.rds"))
colnames(multigroup)
glimpse(multigroup)
unique(multigroup$item_task)

# define tasks for EFA (remove ha)
efa_tasks <- c("hf", "math", "matrix", "mg", "mrot", "sds", "tom", "trog", "vocab")

```

### run ages

```{r}
# create sites
sites <- c("ca_pilot", "co_pilot", "de_pilot")

run_ages <- read_rds(here(glue("01_fetched_data/run_data.rds"))) |>
  select(site, task_id, user_id, run_id, age) |>
  filter(site %in% sites)

ages <- run_ages |>
  group_by(user_id) |>
  summarise(age = mean(age, na.rm=TRUE))
```

### create wide format (one row per participant, one column per task) 

```{r}
# long to wide — one row per participant, one column per task
scores_wide <- multigroup |>
  group_by(user_id, site, item_task) |>
  summarise(metric_value = mean(metric_value, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(names_from = item_task, values_from = metric_value)

# clean names and join age 
scores_wide_mat <- scores_wide |>
  janitor::clean_names() |>
  left_join(ages, by = "user_id")

```

### check n's

```{r}
scores_wide_mat %>%
  select(all_of(efa_tasks)) %>%
  summarise(
    across(everything(),
           ~round(mean(is.na(.)) * 100, 1),
           .names = "missing_pct_{col}")
  )

# check how many tasks each child completed
scores_wide_mat %>%
  mutate(n_tasks = rowSums(!is.na(select(., all_of(efa_tasks))))) %>%
  count(n_tasks) %>%
  arrange(desc(n_tasks))
```

# Part 1: Complete case EFA

### EFA for complete cases - participants with all 9 tasks

```{r}

# select participants with no missing values across the 9 tasks
efa_complete <- scores_wide_mat %>%
  select(all_of(efa_tasks)) %>%
  drop_na() %>%
  mutate(across(everything(), as.numeric))  # Ensure all columns are numeric

# number of complete cases
nrow(efa_complete)

```

### complete case: EFA - complete case sample (psych)

```{r}
library(psych)
psych::KMO(efa_complete) # ha below 0.5 - doesn't share enough variance with the other items - remove.
cortest.bartlett(cor(efa_complete), n = nrow(efa_complete))

# Scree + parallel analysis
fa.parallel(efa_complete, fa = "fa", fm = "ml")

# EFA, 3 fa
efa_result_1 <- fa(efa_complete, nfactors = 3, fm = "ml", rotate = "oblimin")

# View results
print(efa_result_1, cut = 0.2)
```

### complete case (3fa): re-estimate EFA with lavaan (ESEM-style, allowing cross-loadings)

```{r}
# Standardise complete case data for lavaan
efa_complete_z <- efa_complete %>%
  mutate(across(everything(), scale))

# Define EFA model as a string
efa_model_1 <- 'efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab'

# Fit lavaan EFA model
efa_fit_1 <- cfa(efa_model_1,
                 data = efa_complete_z,
                 estimator = "MLR",
                 rotation = "oblimin")

# View results
summary(efa_fit_1, fit.measures = TRUE, standardized = TRUE)
```

# Part 2: estimating using fiml 

# Note: `psych::fa` provides exploratory loadings via factor analysis (e.g., for initial structure discovery), while `lavaan::cfa` here # is used in an exploratory SEM (ESEM) framework to estimate the same structure confirmatorily, using maximum likelihood with FIML and 
# rotation. This allows direct comparison with later CFA models.

### 5fa

```{r}
# have to standardize to get the model to run in laavan (requires fixed residual variances)
scores_wide_mat_z <- scores_wide_mat %>%
  mutate(across(all_of(efa_tasks), scale))

efa_model_5 <- '
efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 + efa("block1")*F4 + efa("block1")*F5 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_5 <- cfa(efa_model_5,
               data = scores_wide_mat_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_5, fit.measures = TRUE, standardized = TRUE)

# This model runs but many heywood cases (negative variance), NA fit indices, small/unstable loadings, high factor intercorrelations
# Indicating too many factors

```

### 4fa

```{r}
efa_model_4 <- '
efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 + efa("block1")*F4  =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_4 <- cfa(efa_model_4,
               data = scores_wide_mat_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_4, fit.measures = TRUE, standardized = TRUE)

# failed - over-fitting

```

### 3fa

```{r}

efa_model_3 <- '
efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_3 <- cfa(efa_model_3,
               data = scores_wide_mat_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_3, fit.measures = TRUE, standardized = TRUE)

# get loadings
efa_3_loadings <- parameterEstimates(efa_fit_3, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, est = std.all)

# group by highest loading factor
efa_3_grouped <- efa_3_loadings %>%
  group_by(task) %>%
  slice_max(abs(est), n = 1, with_ties = FALSE) %>%
  arrange(factor, desc(abs(est))) %>%
  ungroup()

efa_3_grouped

efa_3_loadings %>%
  filter(abs(est) > 0.2) %>%
  ggplot(aes(x = task, y = est, fill = factor)) +
  geom_col(position = "dodge") +
  labs(x = "Task", y = "Standardised Loading", fill = "Factor") +
  theme_minimal()


```

#### 2fa

```{r}

efa_model_2 <- '
efa("block1")*F1 + efa("block1")*F2 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_2 <- cfa(efa_model_2,
               data = scores_wide_mat_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_2, fit.measures = TRUE, standardized = TRUE)

# get loadings
efa_2_loadings <- parameterEstimates(efa_fit_2, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, est = std.all)

# group by highest loading factor
efa_2_grouped <- efa_2_loadings %>%
  group_by(task) %>%
  slice_max(abs(est), n = 1, with_ties = FALSE) %>%
  arrange(factor, desc(abs(est))) %>%
  ungroup()

efa_2_grouped

efa_2_loadings %>%
  filter(abs(est) > 0.2) %>%
  ggplot(aes(x = task, y = est, fill = factor)) +
  geom_col(position = "dodge") +
  labs(x = "Task", y = "Standardised Loading", fill = "Factor") +
  theme_minimal()

```

### 1 fa

```{r}

efa_model_1 <- '
efa("block1")*F1 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_1 <- cfa(efa_model_1,
               data = scores_wide_mat_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_1, fit.measures = TRUE, standardized = TRUE)

# get loadings
efa_1_loadings <- parameterEstimates(efa_fit_1, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, est = std.all)

# group by highest loading factor
efa_1_grouped <- efa_1_loadings %>%
  group_by(task) %>%
  slice_max(abs(est), n = 1, with_ties = FALSE) %>%
  arrange(factor, desc(abs(est))) %>%
  ungroup()

efa_1_grouped

efa_1_loadings %>%
  filter(abs(est) > 0.2) %>%
  ggplot(aes(x = task, y = est, fill = factor)) +
  geom_col(position = "dodge") +
  labs(x = "Task", y = "Standardised Loading", fill = "Factor") +
  theme_minimal()

```

### compare fit indices - EFA

```{r}

# compare 1-factor vs 2-factor models
anova(fit_1f, fit_2f)

# compare 2-factor vs 3-factor models
anova(fit_2f, fit_3f) # sig improvement (Δχ²(3) = 84.94, p < .001) supports 3-factor model over 2-factor

model_comparison_efa <- tibble(
  model = c("1-factor", "2-factor", "3-factor"),
  chisq = c(fitMeasures(efa_fit_1, "chisq"),
            fitMeasures(efa_fit_2, "chisq"),
            fitMeasures(efa_fit_3, "chisq")),
  df = c(fitMeasures(efa_fit_1, "df"),
         fitMeasures(efa_fit_2, "df"),
         fitMeasures(efa_fit_3, "df")),
  cfi = c(fitMeasures(efa_fit_1, "cfi"),
          fitMeasures(efa_fit_2, "cfi"),
          fitMeasures(efa_fit_3, "cfi")),
  tli = c(fitMeasures(efa_fit_1, "tli"),
          fitMeasures(efa_fit_2, "tli"),
          fitMeasures(efa_fit_3, "tli")),
  rmsea = c(fitMeasures(efa_fit_1, "rmsea"),
            fitMeasures(efa_fit_2, "rmsea"),
            fitMeasures(efa_fit_3, "rmsea")),
  bic = c(fitMeasures(efa_fit_1, "bic"),
          fitMeasures(efa_fit_2, "bic"),
          fitMeasures(efa_fit_3, "bic"))
)

model_comparison_efa

# 3 fa model is the best fitting.

```

### CFA for 3 fa model  

```{r}

model_3f <- '
factor1 =~ hf + mg + math 
factor2 =~ tom + matrix + mrot 
factor3 =~ trog + vocab + sds

# add age regressions
factor1 ~ age
factor2 ~ age
factor3 ~ age
'

fit_3f <- cfa(model_3f, data = scores_wide_mat_z,
              std.lv = TRUE, missing = "fiml",
              fixed.x = FALSE,  # so that it doesn't drop those who are missing age
              bounds = list(lower = 0.001)) # included to avoid heywood cases

summary(fit_3f, fit.measures = TRUE, standardize = TRUE)
```

### de-bugging why 370 cases are deleted because of missing age

```{r}
sum(is.na(scores_wide_mat_z$age))

scores_wide_mat_z %>%
  select(hf, mg, math, tom, matrix, mrot, trog, vocab, sds, age) %>%
  summarise_all(~ sum(is.na(.)))

```

### path diagram

```{r}
layout <- matrix(nrow = 5, ncol = 11, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "tom", "matrix", "mrot", NA, "trog", "vocab", "sds",
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  "factor1", NA, NA, NA, "factor2", NA, NA, NA, "factor3", NA, NA,
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  NA, NA, NA, NA, "age", NA, NA, NA, NA, NA, NA
))

graph_sem(fit_3f, layout = layout, text_size = 2.5)

```

### CFA for 2 fa model  

```{r}
model_2f <- '
factor1 =~ hf + mg + math 
factor2 =~ trog + vocab + tom + sds + matrix + mrot

# Add age regressions
factor1 ~ age
factor2 ~ age
'

fit_2f <- cfa(model_2f, data = scores_wide_mat_z,
              std.lv = TRUE, missing = "fiml",
               fixed.x = FALSE,
              bounds = list(lower = 0.001)) # included to avoid heywood cases

summary(fit_2f, fit.measures = TRUE, standardize = TRUE)
```

### path diagram

```{r}
layout <- matrix(nrow = 5, ncol = 10, byrow = TRUE, data = c(
  "hf",    "mg",    "math",   NA,    "sds", "tom",  "matrix", "mrot",  "trog", "vocab",
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  "factor1", NA,    NA,       NA,    NA,  "factor2", NA,    NA,      NA,     NA,
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  NA,      NA,      NA,       NA,  "age", NA,     NA,       NA,      NA,     NA
))

graph_sem(fit_2f, layout = layout, text_size = 2.5)

```

### CFA for 1 fa

```{r}
model_1f <- '
factor1 =~ mg + math + sds + tom + matrix + mrot + trog + vocab + hf

# Add age regressions
factor1 ~ age
'

fit_1f <- cfa(model_1f, data = scores_wide_mat_z,
              std.lv = TRUE, missing = "fiml",
               fixed.x = FALSE,
              bounds = list(lower = 0.001)) # included to avoid heywood cases

summary(fit_1f, fit.measures = TRUE, standardize = TRUE)
```

### path diagram

```{r}
layout <- matrix(nrow = 5, ncol = 10, byrow = TRUE, data = c(
  "hf",    "mg",    "math",   "sds", "tom",  "matrix", "mrot",  "trog", "vocab", NA,
  NA,      NA,      NA,       NA,    NA,     NA,       NA,      NA,     NA,     NA,
  "factor1", NA,    NA,       NA,    NA,     NA,       NA,      NA,     NA,     NA,
  NA,      NA,      NA,       NA,    NA,     NA,       NA,      NA,     NA,     NA,
  NA,      NA,      NA,       NA,    "age",  NA,       NA,      NA,     NA,     NA
))

graph_sem(fit_1f, layout = layout, text_size = 2.5)

# 3 factor model is unstable; revert to 2 factor model.

```

### model comparison - CFA models

```{r}
model_comparison_cfa <- tibble(
  model = c("model_3f", "model_2f", "model_1f"),
  chisq = c(fitMeasures(fit_3f, "chisq"),
            fitMeasures(fit_2f, "chisq"),
            fitMeasures(fit_1f, "chisq")),
  df = c(fitMeasures(fit_3f, "df"),
         fitMeasures(fit_2f, "df"),
         fitMeasures(fit_1f, "df")),
  cfi = c(fitMeasures(fit_3f, "cfi"),
          fitMeasures(fit_2f, "cfi"),
          fitMeasures(fit_1f, "cfi")),
  tli = c(fitMeasures(fit_3f, "tli"),
          fitMeasures(fit_2f, "tli"),
          fitMeasures(fit_1f, "tli")),
  rmsea = c(fitMeasures(fit_3f, "rmsea"),
            fitMeasures(fit_2f, "rmsea"),
            fitMeasures(fit_1f, "rmsea")),
  bic = c(fitMeasures(fit_3f, "bic"),
          fitMeasures(fit_2f, "bic"),
          fitMeasures(fit_1f, "bic"))
)

model_comparison_cfa

# 3 fa best performing
```

## Measurement invariance (not working at the mo)

```{r}
# 3 fa model with age removed
model_3f_mi <- '
factor1 =~ hf + mg + math 
factor2 =~ tom + matrix + mrot 
factor3 =~ trog + vocab + sds
'

fit_configural <- cfa(
  model_3f_mi,
  data = scores_wide_mat_z,
  group = "site",
  missing = "fiml",
  std.lv = TRUE
)

lavInspect(fit_configural, "coverage") # shows proportion of pairwise non-missing cases for each variable pair within each site
# note: columbia is a problem: Near-zero coverage for mrot, sds, and tom.

# not working - too much missingness across 9 tasks

# check group sizes
scores_wide_mat_z %>%
  group_by(site) %>%
  summarise(
    n_total = n(),
    n_complete = sum(complete.cases(across(c(hf, mg, math, tom, matrix, mrot, trog, vocab, sds))))
  )

# Germany only because it has most data across 9 tasks
scores_de <- scores_wide_mat_z %>%
  filter(site == "de_pilot")

fit_3f_mi_de <- cfa(model_3f_mi, data = scores_de, std.lv = TRUE, missing = "fiml")
summary(fit_3f_mi_de, fit.measures = TRUE, standardized = TRUE)

# Examining Columbia more closely
scores_wide_mat_z %>%
  filter(site == "co_pilot") %>%
  summarise(across(c(hf, mg, math, tom, matrix, mrot, trog, vocab, sds),
                   ~ sum(!is.na(.))))
lavInspect(fit_configural, "coverage")$co_pilot
coverage <- lavInspect(fit_configural, "coverage")$co_pilot
sum(coverage < 0.10)

```

## By site - 3 factor model

### Columbia

```{r}
# filter data - co_pilot
scores_co <- scores_wide_mat_z %>%
  filter(site == "co_pilot")

# define model 
model_3f_co <- '
factor1 =~ hf + mg + math
factor2 =~ tom + matrix + mrot
factor3 =~ trog + vocab + sds

factor1 ~ age
factor2 ~ age
factor3 ~ age
'

# fit model
fit_3f_co <- cfa(model_3f_co,
                 data = scores_co,
                 std.lv = TRUE,
                 fixed.x = FALSE,
                 missing = "fiml",  
                 bounds = list(lower = 0.001))  # avoid heywood cases

summary(fit_3f_co, fit.measures = TRUE, standardized = TRUE)

layout <- matrix(nrow = 5, ncol = 11, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "tom", "matrix", "mrot", NA, "trog", "vocab", "sds",
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  "factor1", NA, NA, NA, "factor2", NA, NA, NA, "factor3", NA, NA,
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  NA, NA, NA, NA, "age", NA, NA, NA, NA, NA, NA
))

graph_sem(fit_3f_co, layout = layout, text_size = 2.5)

# Note: “370 cases were deleted due to missing values in exogenous variable(s), while fixed.x = TRUE.” - check why age is missing.

```

### Germany

```{r}
scores_de <- scores_wide_mat_z %>%
  filter(site == "de_pilot")

# define model 
model_3f_de <- '
factor1 =~ hf + mg + math
factor2 =~ tom + matrix + mrot
factor3 =~ trog + vocab + sds

factor1 ~ age
factor2 ~ age
factor3 ~ age
'

# fit model
fit_3f_de <- cfa(model_3f_de,
                 data = scores_de,
                 fixed.x = FALSE,
                 std.lv = TRUE,
                 missing = "fiml", 
                 bounds = list(lower = 0.001))  

summary(fit_3f_de, fit.measures = TRUE, standardized = TRUE)

layout <- matrix(nrow = 5, ncol = 11, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "tom", "matrix", "mrot", NA, "trog", "vocab", "sds",
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  "factor1", NA, NA, NA, "factor2", NA, NA, NA, "factor3", NA, NA,
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  NA, NA, NA, NA, "age", NA, NA, NA, NA, NA, NA
))

graph_sem(fit_3f_de, layout = layout, text_size = 2.5)


```

### Canada

```{r}
scores_ca <- scores_wide_mat_z %>%
  filter(site == "ca_pilot")

# define model 
model_3f_ca <- '
factor1 =~ hf + mg + math
factor2 =~ tom + matrix + mrot
factor3 =~ trog + vocab + sds

factor1 ~ age
factor2 ~ age
factor3 ~ age
'

# fit model
fit_3f_ca <- cfa(model_3f_ca,
                 data = scores_ca,
                 fixed.x = FALSE,
                 std.lv = TRUE,
                 missing = "fiml", 
                 bounds = list(lower = 0.001))  

summary(fit_3f_ca, fit.measures = TRUE, standardized = TRUE)

layout <- matrix(nrow = 5, ncol = 11, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "tom", "matrix", "mrot", NA, "trog", "vocab", "sds",
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  "factor1", NA, NA, NA, "factor2", NA, NA, NA, "factor3", NA, NA,
  NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
  NA, NA, NA, NA, "age", NA, NA, NA, NA, NA, NA
))

graph_sem(fit_3f_ca, layout = layout, text_size = 2.5)

```
# Using cvsem()
```{r}
install.packages("cvsem")
library(cvsem)
ls("package:cvsem")


# prep models
efa_models <- list(
  efa_1f = 'efa("block1")*F1 =~ hf + mg + math + matrix + mrot + sds + tom + trog + vocab',
  efa_2f = 'efa("block1")*F1 + efa("block1")*F2 =~ hf + mg + math + matrix + mrot + sds + tom + trog + vocab',
  efa_3f = 'efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 =~ hf + mg + math + matrix + mrot + sds + tom + trog + vocab',
  efa_4f = 'efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 + efa("block1")*F4 =~ hf + mg + math + matrix + mrot + sds + tom + trog + vocab',
  efa_5f = 'efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 + efa("block1")*F4 + efa("block1")*F5 =~ hf + mg + math + matrix + mrot + sds + tom + trog + vocab'
)

Models <- cvgather(
  model.syntax = efa_models,
  data = scores_wide_mat_z,
  estimator = "MLR",
  missing = "fiml",
  rotation = "oblimin",
  model.name = names(efa_models)
)

cv_results <- cvsem(
  Models = Models,
  data = scores_wide_mat_z,
  folds = 10,
  parallel = FALSE
)

summary(cv_results)
plot(cv_results)

```
### this is not working (getting this error: Error in FUN(X[[i]], ...) : object 'unique_names' not found), trying a different way
```{r}

library(cvsem)
# define list of named model strings
efa_models <- setNames(
  list(
    efa_model_1,
    efa_model_2,
    efa_model_3,
    efa_model_4,
    efa_model_5
  ),
  nm = c("efa_1f", "efa_2f", "efa_3f", "efa_4f", "efa_5f")
)

# gather into cvsem-compatible structure
Models <- cvgather(
  model.syntax = efa_models,
  data = scores_wide_mat_z,
  estimator = "MLR",
  missing = "fiml",
  rotation = "oblimin"
)

cv_results <- cvsem(
  Models = Models,
  data = scores_wide_mat_z,
  folds = 10,
  parallel = TRUE
)

# still not working

```






























# OLD

# COMPLETE CASE (removed)

### complete case: print loadings

```{r}
loadings_above_0.2 <- parameterEstimates(efa_fit_1, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, loading = std.all) %>%
  filter(abs(loading) > 0.2) %>%
  arrange(factor, desc(abs(loading)))

print(loadings_above_0.2)

```

### complete case: compare to 2 fa strucutre, complete case

```{r}
# EFA, 2 fa
efa_result_2 <- fa(efa_complete, nfactors = 2, fm = "ml", rotate = "oblimin")

# View results
print(efa_result_2, cut = 0.2)

# Define EFA model as a string
efa_model_2 <- 'efa("block1")*F1 + efa("block1")*F2 =~ 
  ha + hf + math + matrix + mg + mrot + sds + tom + trog + vocab'

# lavaan EFA model
efa_fit_2 <- cfa(efa_model_2,
                 data = efa_complete_z,
                 estimator = "MLR",
                 rotation = "oblimin")

summary(efa_fit_2, fit.measures = TRUE, standardized = TRUE)

```

### complete case: compare 2 fa and 3 fa - complete case 

```{r}

compare_cc <- tibble::tibble(
  Model = c("3-factor", "2-factor"),
  TLI = c(efa_result_1$TLI, efa_result_2$TLI),
  RMSEA = c(efa_result_1$RMSEA[1], efa_result_2$RMSEA[1]),
  BIC = c(efa_result_1$BIC, efa_result_2$BIC),
  RMSR = c(efa_result_1$rms, efa_result_2$rms),
  Proportion_Var = c(sum(efa_result_1$Vaccounted[2, ]),
                     sum(efa_result_2$Vaccounted[2, ]))
)

print(compare_cc)

# 3 fa better overall

```

### complete case: compare loadings across 2 and 3 fa structures

```{r}
get_loadings <- function(fit, threshold = 0.2) {
  parameterEstimates(fit, standardized = TRUE) %>%
    filter(op == "=~") %>%
    select(factor = lhs, task = rhs, loading = std.all) %>%
    filter(abs(loading) > threshold) %>%
    arrange(task, desc(abs(loading)))
}

loadings_3f <- get_loadings(efa_fit_1)
loadings_2f <- get_loadings(efa_fit_2)

print(loadings_3f)
print(loadings_2f)

```


```