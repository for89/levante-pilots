---
title: "SEM_all_tasks_updated_july2025"
format: html
editor: visual
---
```{r setup}
library(tidyverse)
library(here)
library(glue)
library(lavaan)
library(tidySEM)
library(ggthemes)
library(dplyr)
library(tidyr)
library(knitr)

source(here("02_score_data","irt_helpers.R"))
source(here("03_summaries", "plotting_helper.R"))
source(here("03_explore_tasks/explore_helper.R"))
```

# Part 1: EFA - 9 core tasks

### load thetas for 9 core tasks (not ROAR, mefs or ha)

```{r}
multigroup <- read_rds(here("02_scoring_outputs","scores",
                             "multigroup_scores.rds"))
colnames(multigroup)
glimpse(multigroup)
unique(multigroup$item_task)

# define tasks for EFA (remove ha)
efa_tasks <- c("hf", "math", "matrix", "mg", "mrot", "sds", "tom", "trog", "vocab")

```

### run ages

```{r}
# create sites
sites <- c("ca_pilot", "co_pilot", "de_pilot")

run_ages <- read_rds(here(glue("01_fetched_data/run_data.rds"))) |>
  select(site, task_id, user_id, run_id, age) |>
  filter(site %in% sites)

ages <- run_ages |>
  group_by(user_id) |>
  summarise(age = mean(age, na.rm=TRUE))
```

### create wide format (one row per participant, one column per task) 

```{r}
# long to wide — one row per participant, one column per task
scores_wide <- multigroup |>
  group_by(user_id, site, item_task) |>
  summarise(metric_value = mean(metric_value, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(names_from = item_task, values_from = metric_value)

# clean names and join age 
scores_wide_mat <- scores_wide |>
  janitor::clean_names() |>
  left_join(ages, by = "user_id")

```

### check n's

```{r}
scores_wide_mat %>%
  select(all_of(efa_tasks)) %>%
  summarise(
    across(everything(),
           ~round(mean(is.na(.)) * 100, 1),
           .names = "missing_pct_{col}")
  )

# check how many tasks each child completed
scores_wide_mat %>%
  mutate(n_tasks = rowSums(!is.na(select(., all_of(efa_tasks))))) %>%
  count(n_tasks) %>%
  arrange(desc(n_tasks))
```

# Part 1: Complete case EFA

### EFA for complete cases - participants with all 9 tasks

```{r}

# select participants with no missing values across the 9 tasks
efa_complete <- scores_wide_mat %>%
  select(all_of(efa_tasks)) %>%
  drop_na() %>%
  mutate(across(everything(), as.numeric))  # Ensure all columns are numeric

# number of complete cases
nrow(efa_complete)

```

### complete case: EFA - complete case sample (psych)

```{r}
library(psych)
psych::KMO(efa_complete) # ha below 0.5 - doesn't share enough variance with the other items - remove.
cortest.bartlett(cor(efa_complete), n = nrow(efa_complete))

# Scree + parallel analysis
fa.parallel(efa_complete, fa = "fa", fm = "ml")

# EFA, 3 fa
efa_result_1 <- fa(efa_complete, nfactors = 3, fm = "ml", rotate = "oblimin")

# View results
print(efa_result_1, cut = 0.2)
```

### complete case (3fa): re-estimate EFA with lavaan (ESEM-style, allowing cross-loadings)

```{r}
# Standardise complete case data for lavaan
efa_complete_z <- efa_complete %>%
  mutate(across(everything(), scale))

# Define EFA model as a string
efa_model_1 <- 'efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 =~ 
  hf + math + matrix + mg + mrot + sds + tom + trog + vocab'

# Fit lavaan EFA model
efa_fit_1 <- cfa(efa_model_1,
                 data = efa_complete_z,
                 estimator = "MLR",
                 rotation = "oblimin")

# View results
summary(efa_fit_1, fit.measures = TRUE, standardized = TRUE)
```

# Part 2: estimating using fiml

```{r}

# z-scored version of EFA tasks
scores_wide_mat_z <- scores_wide_mat %>%
  mutate(across(all_of(efa_tasks), scale))

run_efa_model <- function(n_factors, data, tasks) {
  factor_names <- paste0("F", 1:n_factors)
  lhs <- paste(factor_names, collapse = " + ")
  rhs <- paste(tasks, collapse = " + ")
  model_string <- glue::glue('efa("block1")*{lhs} =~ {rhs}')
  
  tryCatch({
    fit <- lavaan::cfa(model_string,
                       data = data,
                       estimator = "MLR",
                       missing = "FIML",
                       rotation = "oblimin")
    
    fit_measures <- lavaan::fitMeasures(fit, c("chisq", "df", "cfi", "tli", "rmsea", "bic"))
    
    loadings <- lavaan::parameterEstimates(fit, standardized = TRUE) %>%
      dplyr::filter(op == "=~") %>%
      dplyr::select(lhs, rhs, est = std.all) %>%
      dplyr::mutate(n_factors = n_factors)
    
    return(list(fit = fit, fit_measures = fit_measures, loadings = loadings))
    
  }, error = function(e) {
    warning(glue::glue("EFA model with {n_factors} factors failed: {e$message}"))
    return(NULL)
  })
}

```

### running models with 1-5 factors

```{r}
# Scree + parallel analysis
fa.parallel(scores_wide_mat_z, fa = "fa", fm = "ml")

# task list
efa_tasks <- c("hf", "math", "matrix", "mg", "mrot", "sds", "tom", "trog", "vocab")  # ha removed

# run models
efa_results <- purrr::map(1:5, ~run_efa_model(.x, data = scores_wide_mat_z, tasks = efa_tasks))
names(efa_results) <- paste0("efa_", 1:5) # only 1-3 running. 4 and 5 are failing (not enough data, over-parameterized)

# remove NULL entries
efa_results_clean <- efa_results[!purrr::map_lgl(efa_results, is.null)]

length(efa_results_clean)  
names(efa_results_clean)


```

### compare

```{r}
# check each fit_measures length
efa_fits_df <- efa_results_clean |>
  purrr::keep(~ !is.null(.x$fit_measures) && length(.x$fit_measures) == 6) |>
  purrr::imap_dfr(~{
    tibble::as_tibble_row(.x$fit_measures) |> dplyr::mutate(model = .y)
  })
print(efa_fits_df)

# 2 fa structure seems to be the best fitting

```

### print loadings - 2 factor model

```{r}
efa_2_loadings <- efa_results_clean[["efa_2"]]$loadings

efa_2_loadings %>%
  filter(abs(est) > 0.2) %>%
  arrange(lhs, desc(abs(est)))

```

### graph - 2 factor model

```{r}
efa_2_loadings %>%
  filter(abs(est) > 0.2) %>%
  ggplot(aes(x = rhs, y = est, fill = lhs)) +
  geom_col(position = "dodge") +
  labs(x = "Task", y = "Standardised Loading", fill = "Factor") +
  theme_minimal()

```

### CFA for 2 factor model

```{r}
model_2f <- '
factor1 =~ hf + math + matrix + mg + mrot
factor2 =~ sds + tom + trog + vocab

# Add age regressions
factor1 ~ age
factor2 ~ age
'

fit_2f <- cfa(model_2f, data = scores_wide_mat_z,
              std.lv = TRUE, missing = "fiml",
              bounds = list(lower = 0.001)) # included to avoid heywood cases

summary(fit_2f, fit.measures = TRUE, standardize = TRUE)
```

### path diagram

```{r}
# check vars
lavNames(fit_2f, type = "ov")   # observed variables 
lavNames(fit_2f, type = "lv")   # latent variables 
lavNames(fit_2f, type = "all")  # all variables

layout <- matrix(nrow = 5, ncol = 10, byrow = TRUE, data = c(
  "hf",    "mg",    "math",   "sds", NA,  "tom",  "matrix", "mrot",  "trog", "vocab",
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  "factor1", NA,    NA,       NA,    NA,  "factor2", NA,    NA,      NA,     NA,
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  NA,      NA,      NA,       NA,  "age", NA,     NA,       NA,      NA,     NA
))

graph_sem(fit_2f, layout = layout, text_size = 2.5)

# dubug
library(tidySEM)
get_nodes(fit_2f)

```

### try alternative diagram

```{r}
library(tidySEM)
graph <- tidySEM::prepare_graph(fit_2f)
str(graph)

graph$layout <- graph$layout |>
  mutate(
    x = case_when(
      label %in% c("hf", "mg", "math", "sds") ~ 1,
      label == "factor1" ~ 2,
      label %in% c("tom", "matrix", "mrot") ~ 3,
      label == "trog" ~ 4,
      label == "vocab" ~ 5,
      label == "factor2" ~ 6,
      TRUE ~ 0
    ),
    y = case_when(
      label == "hf" ~ 4,
      label == "mg" ~ 3,
      label == "math" ~ 2,
      label == "sds" ~ 1,
      label == "factor1" ~ 2.5,
      label == "tom" ~ 4,
      label == "matrix" ~ 3,
      label == "mrot" ~ 2,
      label == "trog" ~ 1,
      label == "vocab" ~ 0,
      label == "factor2" ~ 2,
      TRUE ~ NA_real_
    )
  )
plot(graph)


```

### 3 factor model

### print loadings
```{r}
efa_3_loadings <- efa_results_clean[["efa_3"]]$loadings

efa_3_loadings %>%
  filter(abs(est) > 0.2) %>%
  arrange(lhs, desc(abs(est)))

# nothing loading on factor 2 - structure unstable
```

```{r}
efa_3_loadings %>%
  filter(abs(est) > 0.2) %>%
  ggplot(aes(x = rhs, y = est, fill = lhs)) +
  geom_col(position = "dodge") +
  labs(x = "Task", y = "Standardised Loading", fill = "Factor") +
  theme_minimal()

```

```{r}

model_3f <- '
factor1 =~ mg + math + sds + tom + matrix + mrot + trog + vocab
factor2 =~ hf

# Add age regressions
factor1 ~ age
factor2 ~ age
'

fit_3f <- cfa(model_3f, data = scores_wide_mat_z,
              std.lv = TRUE, missing = "fiml",
              bounds = list(lower = 0.001)) # included to avoid heywood cases

summary(fit_3f, fit.measures = TRUE, standardize = TRUE)
```

### path diagram

```{r}
layout <- matrix(nrow = 5, ncol = 10, byrow = TRUE, data = c(
  "hf",    "mg",    "math",   "sds", NA,  "tom",  "matrix", "mrot",  "trog", "vocab",
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  "factor1", NA,    NA,       NA,    NA,  "factor2", NA,    NA,      NA,     NA,
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  NA,      NA,      NA,       NA,  "age", NA,     NA,       NA,      NA,     NA
))

graph_sem(fit_3f, layout = layout, text_size = 2.5)

# 3 factor model is unstable; revert to 2 factor model.

```

## By site - 2 factor model

### Columbia

```{r}
# filter data - co_pilot
scores_co <- scores_wide_mat_z %>%
  filter(site == "co_pilot")

# define model 
model_2f_co <- '
factor1 =~ hf + mg + math + sds
factor2 =~ tom + matrix + mrot + trog + vocab

factor1 ~ age
factor2 ~ age
'

# fit model
fit_2f_co <- cfa(model_2f_co,
                 data = scores_co,
                 std.lv = TRUE,
                 missing = "fiml",  
                 bounds = list(lower = 0.001))  # avoid heywood cases

summary(fit_2f_co, fit.measures = TRUE, standardized = TRUE)

layout <- matrix(nrow = 5, ncol = 10, byrow = TRUE, data = c(
  "hf",    "mg",    "math",   "sds", NA,  "tom",  "matrix", "mrot",  "trog", "vocab",
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  "factor1", NA,    NA,       NA,    NA,  "factor2", NA,    NA,      NA,     NA,
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  NA,      NA,      NA,       NA,  "age", NA,     NA,       NA,      NA,     NA
))

graph_sem(fit_2f_co, layout = layout, text_size = 2.5)

# Note: “370 cases were deleted due to missing values in exogenous variable(s), while fixed.x = TRUE.” - check why age is missing.

```

### Germany

```{r}
scores_de <- scores_wide_mat_z %>%
  filter(site == "de_pilot")

# define model 
model_2f_de <- '
factor1 =~ hf + mg + math + sds
factor2 =~ tom + matrix + mrot + trog + vocab

factor1 ~ age
factor2 ~ age
'

# fit model
fit_2f_de <- cfa(model_2f_de,
                 data = scores_de,
                 std.lv = TRUE,
                 missing = "fiml", 
                 bounds = list(lower = 0.001))  

summary(fit_2f_de, fit.measures = TRUE, standardized = TRUE)

layout <- matrix(nrow = 5, ncol = 10, byrow = TRUE, data = c(
  "hf",    "mg",    "math",   "sds", NA,  "tom",  "matrix", "mrot",  "trog", "vocab",
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  "factor1", NA,    NA,       NA,    NA,  "factor2", NA,    NA,      NA,     NA,
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  NA,      NA,      NA,       NA,  "age", NA,     NA,       NA,      NA,     NA
))

graph_sem(fit_2f_de, layout = layout, text_size = 2.5)


```

### Canada

```{r}
scores_ca <- scores_wide_mat_z %>%
  filter(site == "ca_pilot")

# define model 
model_2f_ca <- '
factor1 =~ hf + mg + math + sds
factor2 =~ tom + matrix + mrot + trog + vocab

factor1 ~ age
factor2 ~ age
'

# fit model
fit_2f_ca <- cfa(model_2f_ca,
                 data = scores_ca,
                 std.lv = TRUE,
                 missing = "fiml", 
                 bounds = list(lower = 0.001))  

summary(fit_2f_ca, fit.measures = TRUE, standardized = TRUE)

layout <- matrix(nrow = 5, ncol = 10, byrow = TRUE, data = c(
  "hf",    "mg",    "math",   "sds", NA,  "tom",  "matrix", "mrot",  "trog", "vocab",
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  "factor1", NA,    NA,       NA,    NA,  "factor2", NA,    NA,      NA,     NA,
  NA,      NA,      NA,       NA,    NA,  NA,     NA,       NA,      NA,     NA,
  NA,      NA,      NA,       NA,  "age", NA,     NA,       NA,      NA,     NA
))

graph_sem(fit_2f_ca, layout = layout, text_size = 2.5)

```

# Step 3: IMV to Compare 1-, 2-, and 3-Factor Models

### define models - 1 factor

```{r}
# Install Lijin's package
install.packages("devtools")
devtools::install_github("zhanglj37/imv4sem")
library(imv4sem)
```


```{r}
model_1f <- '
cog =~ hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'
```

### 2 factors

```{r}
model_2f <- '
EF =~ hf + mg + math + sds
Social_cog =~ tom + matrix + mrot + trog + vocab
'
```

### 3 factors

```{r}
model_3f <- '
EF =~ hf + sds + mg
Spatial =~ math + matrix + mrot
Language =~ tom + trog + vocab
'
```

```{r}
```

```{r}
```

```{r}
```



































# OLD

# Invariance testing

### configural (same factor structure across groups, all parameters freely estimated)

```{r}
fit_config_1 <- cfa(model_5, data = scores_wide_mat_z,
                      group = "site", std.lv = TRUE, missing = "fiml",
                      fixed.x = FALSE)

summary(fit_configural, fit.measures = TRUE, standardized = TRUE)
lavInspect(fit_configural, "cor.lv")

# latent factors highly correlated in some groups (>1) causing non-pos definite covariance matrices; try fixing covariances.

# fixing covariances
model_5_nocov <- '
  ef_math =~ hf + mg + math
  social_reason =~ ha + tom + matrix + mrot
  language =~ sds + trog + vocab

  ef_math ~ age
  social_reason ~ age
  language ~ age

  ef_math ~~ 0*social_reason
  ef_math ~~ 0*language
  social_reason ~~ 0*language'

fit_config_2 <- cfa(model_5_nocov, data = scores_wide_mat_z,
                      group = "site", std.lv = TRUE, missing = "fiml",
                      fixed.x = FALSE)

summary(fit_configural, fit.measures = TRUE, standardized = TRUE)

```

### metric (constrain factor loadings to be equal across sites - asking if the relationships between items and factors the same)

```{r}
fit_metric <- cfa(model_5_nocov, data = scores_wide_mat_z,
                  group = "site", std.lv = TRUE, missing = "fiml",
                  fixed.x = FALSE,
                  group.equal = "loadings")

# issue: sparse data - fewer than 10% of participants have observed data for both variables in the pair
lavInspect(fit_metric, "coverage")

# check missingness for co_pilot
scores_wide_mat_z %>%
  group_by(site) %>%
  summarise(across(hf:age, ~ mean(is.na(.)) * 100, .names = "{.col}_missing")) %>%
  ungroup()
# only ~20–35% of children in co_pilot completed each task???

anova(fit_config_2, fit_metric) # metric invariance not supported

```

### scaler (constrain loadings + intercepts to be equal across sites - asking if item baselines the same)

```{r}
fit_scalar <- cfa(model_5_nocov, data = scores_wide_mat_z,
                  group = "site", std.lv = TRUE, missing = "fiml",
                  fixed.x = FALSE,
                  group.equal = c("loadings", "intercepts"))

# same issue as above - fewer than 10% have observed data for both variables in a pair
lavInspect(fit_scalar, "coverage")


anova(fit_metric, fit_scalar) # scalar invariance not supported

```

# COMPLETE CASE (removed)

### complete case: print loadings

```{r}
loadings_above_0.2 <- parameterEstimates(efa_fit_1, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, loading = std.all) %>%
  filter(abs(loading) > 0.2) %>%
  arrange(factor, desc(abs(loading)))

print(loadings_above_0.2)

```

### complete case: compare to 2 fa strucutre, complete case

```{r}
# EFA, 2 fa
efa_result_2 <- fa(efa_complete, nfactors = 2, fm = "ml", rotate = "oblimin")

# View results
print(efa_result_2, cut = 0.2)

# Define EFA model as a string
efa_model_2 <- 'efa("block1")*F1 + efa("block1")*F2 =~ 
  ha + hf + math + matrix + mg + mrot + sds + tom + trog + vocab'

# lavaan EFA model
efa_fit_2 <- cfa(efa_model_2,
                 data = efa_complete_z,
                 estimator = "MLR",
                 rotation = "oblimin")

summary(efa_fit_2, fit.measures = TRUE, standardized = TRUE)

```

### complete case: compare 2 fa and 3 fa - complete case 

```{r}

compare_cc <- tibble::tibble(
  Model = c("3-factor", "2-factor"),
  TLI = c(efa_result_1$TLI, efa_result_2$TLI),
  RMSEA = c(efa_result_1$RMSEA[1], efa_result_2$RMSEA[1]),
  BIC = c(efa_result_1$BIC, efa_result_2$BIC),
  RMSR = c(efa_result_1$rms, efa_result_2$rms),
  Proportion_Var = c(sum(efa_result_1$Vaccounted[2, ]),
                     sum(efa_result_2$Vaccounted[2, ]))
)

print(compare_cc)

# 3 fa better overall

```

### complete case: compare loadings across 2 and 3 fa structures

```{r}
get_loadings <- function(fit, threshold = 0.2) {
  parameterEstimates(fit, standardized = TRUE) %>%
    filter(op == "=~") %>%
    select(factor = lhs, task = rhs, loading = std.all) %>%
    filter(abs(loading) > threshold) %>%
    arrange(task, desc(abs(loading)))
}

loadings_3f <- get_loadings(efa_fit_1)
loadings_2f <- get_loadings(efa_fit_2)

print(loadings_3f)
print(loadings_2f)

```

# Move to EFA with fiml (laavan, 3 fa) ################ OLD

```{r}
# have to standardize to get the model to run in laavan (requires fixed residual variances) (flat with mike/nilam)
scores_wide_mat_z <- scores_wide_mat %>%
  mutate(across(all_of(efa_tasks), scale))

# EFA model string with all 10 tasks
# model estimates 3 factors; 10 tasks are allowed to freely load on all 3 factors. Rotation method (oblimin) controls rotated solution.

efa_model_3 <- '
efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 =~ 
  ha + hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_3 <- cfa(efa_model_3,
               data = scores_wide_mat_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_3, fit.measures = TRUE, standardized = TRUE)

```

### imputed: factor loadings (3 fa)

```{r}
loadings <- parameterEstimates(efa_fit_3, standardized = TRUE) |>
  dplyr::filter(op == "=~") |>  # Keep only factor loadings
  dplyr::select(lhs, rhs, est = std.all)  # lhs = factor, rhs = indicator

# View all loadings
print(loadings)

# View loadings > 0.2
loadings_above_0.2 <- loadings |> 
  dplyr::filter(abs(est) > 0.2) |> 
  dplyr::arrange(lhs, desc(abs(est)))

print(loadings_above_0.2)

```

### with imputation: EFA with fiml (2 fa)

```{r}
efa_model_4 <- '
efa("block1")*F1 + efa("block1")*F2 =~ 
  ha + hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_4 <- cfa(efa_model_4,
                  data = scores_wide_mat_z,
                  estimator = "MLR",
                  missing = "FIML",
                  rotation = "oblimin")

summary(efa_fit_4, fit.measures = TRUE, standardized = TRUE)

```

### print factor loadings (2 fa)

```{r}

loadings <- parameterEstimates(efa_fit_4, standardized = TRUE) |>
  dplyr::filter(op == "=~") |>  # Keep only factor loadings
  dplyr::select(lhs, rhs, est = std.all)  # lhs = factor, rhs = indicator

# View all loadings
print(loadings)

# View loadings > 0.2
loadings_above_0.2 <- loadings |> 
  dplyr::filter(abs(est) > 0.2) |> 
  dplyr::arrange(lhs, desc(abs(est)))

print(loadings_above_0.2)

# 3 fa better overall
```

### compare factor loadings: imputed v complete case

```{r}
# loadings from complete-case model (efa_fit_1)
loadings_cc <- parameterEstimates(efa_fit_1, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(task = rhs, factor = lhs, loading_cc = std.all)

# loadings from fiml-imputed model (efa_fit_3)
loadings_fiml <- parameterEstimates(efa_fit_3, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(task = rhs, factor = lhs, loading_fiml = std.all)

# combine
loadings_comparison <- full_join(loadings_cc, loadings_fiml, by = c("task", "factor")) %>%
  arrange(factor, task)

# remove loadings below 0.2 and round to 3 decimal places 
loadings_comparison_filtered <- loadings_comparison %>%
  mutate(across(c(loading_cc, loading_fiml), ~ ifelse(abs(.) < 0.2, NA, round(., 3))))

# table
print(loadings_comparison_filtered)

# pivot wide
loadings_wide <- loadings_comparison_filtered %>%
  pivot_wider(names_from = factor, values_from = c(loading_cc, loading_fiml))

print(loadings_wide)
```

### path diagram

```{r}
model_5 <- '
ef_math =~ hf + mg + math
social_reason =~ ha + tom + matrix + mrot
language =~ sds + trog + vocab

# add age
ef_math ~ age
social_reason ~ age
language ~ age'

fit_5 <- cfa(model_5, data = scores_wide_mat_z,
           std.lv = TRUE, missing = "fiml",
           bounds = list(lower = 0.001))
# heywood cases still persisting even when residuals are constrained - suggests over-fitting.

summary(fit_5, fit.measures=TRUE, standardize=TRUE)

layout <- matrix(nrow = 3, ncol = 9, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "ha", "tom", "matrix", "mrot", NA,
  NA,   NA,   NA,     NA, NA,   NA,     "sds",   "trog", "vocab",
  "ef_math", NA, NA, NA, "social_reason", NA, "language", NA, NA
))

graph_sem(fit_5, layout = t(layout), text_size = 2.5)
