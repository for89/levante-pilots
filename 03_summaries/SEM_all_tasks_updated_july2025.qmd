---
title: "SEM_all_tasks_updated_july2025"
format: html
editor: visual
---
```{r setup}
library(tidyverse)
library(here)
library(glue)
library(lavaan)
library(tidySEM)
library(ggthemes)
library(dplyr)
library(tidyr)
library(knitr)

source(here("02_score_data","irt_helpers.R"))
source(here("03_summaries", "plotting_helper.R"))
source(here("03_explore_tasks/explore_helper.R"))
```

# Part 1: EFA - 9 core tasks

### load thetas for 9 core tasks (not ROAR or mefs)

```{r}
multigroup <- read_rds(here("02_scoring_outputs","scores",
                             "multigroup_scores.rds"))
colnames(multigroup)
glimpse(multigroup)
unique(multigroup$item_task)

# define tasks for EFA
efa_tasks <- c("ha", "hf", "math", "matrix", "mg", "mrot", "sds", "tom", "trog", "vocab")

```

### run ages

```{r}
# create sites
sites <- c("ca_pilot", "co_pilot", "de_pilot")

run_ages <- read_rds(here(glue("01_fetched_data/run_data.rds"))) |>
  select(site, task_id, user_id, run_id, age) |>
  filter(site %in% sites)

ages <- run_ages |>
  group_by(user_id) |>
  summarise(age = mean(age, na.rm=TRUE))
```

### create wide format (one row per participant, one column per task) 

```{r}
# long to wide â€” one row per participant, one column per task
scores_wide <- multigroup |>
  group_by(user_id, site, item_task) |>
  summarise(metric_value = mean(metric_value, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(names_from = item_task, values_from = metric_value)

# clean names and join age 
scores_wide_mat <- scores_wide |>
  janitor::clean_names() |>
  left_join(ages, by = "user_id")

```

### check n's

```{r}
scores_wide_mat %>%
  select(all_of(efa_tasks)) %>%
  summarise(
    across(everything(),
           ~round(mean(is.na(.)) * 100, 1),
           .names = "missing_pct_{col}")
  )

# check how many tasks each child completed
scores_wide_mat %>%
  mutate(n_tasks = rowSums(!is.na(select(., all_of(efa_tasks))))) %>%
  count(n_tasks) %>%
  arrange(desc(n_tasks))

# very low number of complete cases (i.e., all 10 tasks)

```

### EFA for complete cases - participants with all 10 tasks

```{r}

# select participants with no missing values across the 9 tasks
efa_complete <- scores_wide_mat %>%
  select(all_of(efa_tasks)) %>%
  drop_na() %>%
  mutate(across(everything(), as.numeric))  # Ensure all columns are numeric

# number of complete cases
nrow(efa_complete)

```

### complete case: EFA - complete case sample (psych)

```{r}
library(psych)
psych::KMO(efa_complete) # ha below 0.5 - doesn't share enough variance with the other items
cortest.bartlett(cor(efa_complete), n = nrow(efa_complete))

# Scree + parallel analysis
fa.parallel(efa_complete, fa = "fa", fm = "ml")

# EFA, 3 fa
efa_result_1 <- fa(efa_complete, nfactors = 3, fm = "ml", rotate = "oblimin")

# View results
print(efa_result_1, cut = 0.2)
```

### complete case: re-estimate EFA with lavaan (ESEM-style, allowing cross-loadings)

```{r}
# Standardise complete case data for lavaan
efa_complete_z <- efa_complete %>%
  mutate(across(everything(), scale))

# Define EFA model as a string
efa_model_1 <- 'efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 =~ 
  ha + hf + math + matrix + mg + mrot + sds + tom + trog + vocab'

# Fit lavaan EFA model
efa_fit_1 <- cfa(efa_model_1,
                 data = efa_complete_z,
                 estimator = "MLR",
                 rotation = "oblimin")

# View results
summary(efa_fit_1, fit.measures = TRUE, standardized = TRUE)
```

### complete case: print loadings

```{r}
loadings_above_0.2 <- parameterEstimates(efa_fit_1, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(factor = lhs, task = rhs, loading = std.all) %>%
  filter(abs(loading) > 0.2) %>%
  arrange(factor, desc(abs(loading)))

print(loadings_above_0.2)

```

### complete case: compare to 2 fa strucutre, complete case

```{r}
# EFA, 2 fa
efa_result_2 <- fa(efa_complete, nfactors = 2, fm = "ml", rotate = "oblimin")

# View results
print(efa_result_2, cut = 0.2)

# Define EFA model as a string
efa_model_2 <- 'efa("block1")*F1 + efa("block1")*F2 =~ 
  ha + hf + math + matrix + mg + mrot + sds + tom + trog + vocab'

# lavaan EFA model
efa_fit_2 <- cfa(efa_model_2,
                 data = efa_complete_z,
                 estimator = "MLR",
                 rotation = "oblimin")

summary(efa_fit_2, fit.measures = TRUE, standardized = TRUE)

```

### complete case: compare 2 fa and 3 fa - complete case 

```{r}

compare_cc <- tibble::tibble(
  Model = c("3-factor", "2-factor"),
  TLI = c(efa_result_1$TLI, efa_result_2$TLI),
  RMSEA = c(efa_result_1$RMSEA[1], efa_result_2$RMSEA[1]),
  BIC = c(efa_result_1$BIC, efa_result_2$BIC),
  RMSR = c(efa_result_1$rms, efa_result_2$rms),
  Proportion_Var = c(sum(efa_result_1$Vaccounted[2, ]),
                     sum(efa_result_2$Vaccounted[2, ]))
)

print(compare_cc)

# 3 fa better overall

```

### complete case: compare loadings across 2 and 3 fa structures

```{r}
get_loadings <- function(fit, threshold = 0.2) {
  parameterEstimates(fit, standardized = TRUE) %>%
    filter(op == "=~") %>%
    select(factor = lhs, task = rhs, loading = std.all) %>%
    filter(abs(loading) > threshold) %>%
    arrange(task, desc(abs(loading)))
}

loadings_3f <- get_loadings(efa_fit_1)
loadings_2f <- get_loadings(efa_fit_2)

print(loadings_3f)
print(loadings_2f)

```

### EFA with fiml (laavan, 3 fa)

```{r}
# have to standardize to get the model to run in laavan (requires fixed residual variances) (flat with mike/nilam)
scores_wide_mat_z <- scores_wide_mat %>%
  mutate(across(all_of(efa_tasks), scale))

# EFA model string with all 10 tasks
# model estimates 3 factors; 10 tasks are allowed to freely load on all 3 factors. Rotation method (oblimin) controls rotated solution.

efa_model_3 <- '
efa("block1")*F1 + efa("block1")*F2 + efa("block1")*F3 =~ 
  ha + hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_3 <- cfa(efa_model_3,
               data = scores_wide_mat_z,
               estimator = "MLR",
               missing = "FIML",
               rotation = "oblimin")

summary(efa_fit_3, fit.measures = TRUE, standardized = TRUE)

```

### imputed: factor loadings (3 fa)

```{r}
loadings <- parameterEstimates(efa_fit_3, standardized = TRUE) |>
  dplyr::filter(op == "=~") |>  # Keep only factor loadings
  dplyr::select(lhs, rhs, est = std.all)  # lhs = factor, rhs = indicator

# View all loadings
print(loadings)

# View loadings > 0.2
loadings_above_0.2 <- loadings |> 
  dplyr::filter(abs(est) > 0.2) |> 
  dplyr::arrange(lhs, desc(abs(est)))

print(loadings_above_0.2)

```

### with imputation: EFA with fiml (2 fa)

```{r}
efa_model_4 <- '
efa("block1")*F1 + efa("block1")*F2 =~ 
  ha + hf + math + matrix + mg + mrot + sds + tom + trog + vocab
'

efa_fit_4 <- cfa(efa_model_4,
                  data = scores_wide_mat_z,
                  estimator = "MLR",
                  missing = "FIML",
                  rotation = "oblimin")

summary(efa_fit_4, fit.measures = TRUE, standardized = TRUE)

```

### print factor loadings (2 fa)

```{r}

loadings <- parameterEstimates(efa_fit_4, standardized = TRUE) |>
  dplyr::filter(op == "=~") |>  # Keep only factor loadings
  dplyr::select(lhs, rhs, est = std.all)  # lhs = factor, rhs = indicator

# View all loadings
print(loadings)

# View loadings > 0.2
loadings_above_0.2 <- loadings |> 
  dplyr::filter(abs(est) > 0.2) |> 
  dplyr::arrange(lhs, desc(abs(est)))

print(loadings_above_0.2)

# 3 fa better overall
```

### compare factor loadings: imputed v complete case

```{r}
# loadings from complete-case model (efa_fit_1)
loadings_cc <- parameterEstimates(efa_fit_1, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(task = rhs, factor = lhs, loading_cc = std.all)

# loadings from fiml-imputed model (efa_fit_3)
loadings_fiml <- parameterEstimates(efa_fit_3, standardized = TRUE) %>%
  filter(op == "=~") %>%
  select(task = rhs, factor = lhs, loading_fiml = std.all)

# combine
loadings_comparison <- full_join(loadings_cc, loadings_fiml, by = c("task", "factor")) %>%
  arrange(factor, task)

# remove loadings below 0.2 and round to 3 decimal places 
loadings_comparison_filtered <- loadings_comparison %>%
  mutate(across(c(loading_cc, loading_fiml), ~ ifelse(abs(.) < 0.2, NA, round(., 3))))

# table
print(loadings_comparison_filtered)

# pivot wide
loadings_wide <- loadings_comparison_filtered %>%
  pivot_wider(names_from = factor, values_from = c(loading_cc, loading_fiml))

print(loadings_wide)
```

### path diagram

```{r}
model_5 <- '
ef_math =~ hf + mg + math
social_reason =~ ha + tom + matrix + mrot
language =~ sds + trog + vocab

# add age
ef_math ~ age
social_reason ~ age
language ~ age'

fit_5 <- cfa(model_5, data = scores_wide_mat_z,
           std.lv = TRUE, missing = "fiml",
           bounds = list(lower = 0.001))
# heywood cases still persisting even when residuals are constrained - suggests over-fitting.

summary(fit_5, fit.measures=TRUE, standardize=TRUE)

layout <- matrix(nrow = 3, ncol = 9, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "ha", "tom", "matrix", "mrot", NA,
  NA,   NA,   NA,     NA, NA,   NA,     "sds",   "trog", "vocab",
  "ef_math", NA, NA, NA, "social_reason", NA, "language", NA, NA
))

graph_sem(fit_5, layout = t(layout), text_size = 2.5)

```

### by site

### Columbia

```{r}
# check n
scores_wide_mat_z %>%
  filter(site == "co_pilot") %>%
  summarise(n_total = n_distinct(user_id))  #1,069 

model_6_co <- '
ef_math =~ hf + mg + math
social_reason =~ ha + tom + matrix + mrot
language =~ sds + trog + vocab

# add age
ef_math ~ age
social_reason ~ age
language ~ age'

fit_6_co <- cfa(model_6_co, 
                filter(scores_wide_mat_z, site == "co_pilot"),
                std.lv = TRUE, missing = "fiml",
                bounds = list(lower = 0.001))

summary(fit_6_co, fit.measures=TRUE, standardize=TRUE)

layout <- matrix(nrow = 3, ncol = 9, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "ha", "tom", "matrix", "mrot", NA,
  NA,   NA,   NA,     NA, NA,   NA,     "sds",   "trog", "vocab",
  "ef_math", NA, NA, NA, "social_reason", NA, "language", NA, NA
))

graph_sem(fit_6_co, layout = t(layout), text_size = 2.5)

```
### Germany

```{r}
# check n
scores_wide_mat_z %>%
  filter(site == "de_pilot") %>%
  summarise(n_total = n_distinct(user_id))  #320

model_7_de <- '
ef_math =~ hf + mg + math
social_reason =~ ha + tom + matrix + mrot
language =~ sds + trog + vocab

# add age
ef_math ~ age
social_reason ~ age
language ~ age'

fit_7_de <- cfa(model_7_de, 
                filter(scores_wide_mat_z, site == "de_pilot"),
                std.lv = TRUE, missing = "fiml",
                bounds = list(lower = 0.001))

summary(fit_7_de, fit.measures=TRUE, standardize=TRUE)

layout <- matrix(nrow = 3, ncol = 9, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "ha", "tom", "matrix", "mrot", NA,
  NA,   NA,   NA,     NA, NA,   NA,     "sds",   "trog", "vocab",
  "ef_math", NA, NA, NA, "social_reason", NA, "language", NA, NA
))

graph_sem(fit_7_de, layout = t(layout), text_size = 2.5)

```
### Canada

```{r}
# check n
scores_wide_mat_z %>%
  filter(site == "ca_pilot") %>%
  summarise(n_total = n_distinct(user_id))  #84

model_8_ca <- '
ef_math =~ hf + mg + math
social_reason =~ ha + tom + matrix + mrot
language =~ sds + trog + vocab

# add age
ef_math ~ age
social_reason ~ age
language ~ age'

fit_8_ca <- cfa(model_8_ca, 
                filter(scores_wide_mat_z, site == "ca_pilot"),
                std.lv = TRUE, missing = "fiml",
                bounds = list(lower = 0.001))

summary(fit_8_ca, fit.measures=TRUE, standardize=TRUE)

layout <- matrix(nrow = 3, ncol = 9, byrow = TRUE, data = c(
  "hf", "mg", "math", NA, "ha", "tom", "matrix", "mrot", NA,
  NA,   NA,   NA,     NA, NA,   NA,     "sds",   "trog", "vocab",
  "ef_math", NA, NA, NA, "social_reason", NA, "language", NA, NA
))

graph_sem(fit_8_ca, layout = t(layout), text_size = 2.5)

```

# Invariance testing

### configural (same factor structure across groups, all parameters freely estimated)

```{r}
fit_config_1 <- cfa(model_5, data = scores_wide_mat_z,
                      group = "site", std.lv = TRUE, missing = "fiml",
                      fixed.x = FALSE)

summary(fit_configural, fit.measures = TRUE, standardized = TRUE)
lavInspect(fit_configural, "cor.lv")

# latent factors highly correlated in some groups (>1) causing non-pos definite covariance matrices; try fixing covariances.

# fixing covariances
model_5_nocov <- '
  ef_math =~ hf + mg + math
  social_reason =~ ha + tom + matrix + mrot
  language =~ sds + trog + vocab

  ef_math ~ age
  social_reason ~ age
  language ~ age

  ef_math ~~ 0*social_reason
  ef_math ~~ 0*language
  social_reason ~~ 0*language'

fit_config_2 <- cfa(model_5_nocov, data = scores_wide_mat_z,
                      group = "site", std.lv = TRUE, missing = "fiml",
                      fixed.x = FALSE)

summary(fit_configural, fit.measures = TRUE, standardized = TRUE)

```

### metric (constrain factor loadings to be equal across sites - asking if the relationships between items and factors the same)

```{r}
fit_metric <- cfa(model_5_nocov, data = scores_wide_mat_z,
                  group = "site", std.lv = TRUE, missing = "fiml",
                  fixed.x = FALSE,
                  group.equal = "loadings")

# issue: sparse data - fewer than 10% of participants have observed data for both variables in the pair
lavInspect(fit_metric, "coverage")

# check missingness for co_pilot
scores_wide_mat_z %>%
  group_by(site) %>%
  summarise(across(hf:age, ~ mean(is.na(.)) * 100, .names = "{.col}_missing")) %>%
  ungroup()
# only ~20â€“35% of children in co_pilot completed each task???

anova(fit_config_2, fit_metric) # metric invariance not supported

```

### scaler (constrain loadings + intercepts to be equal across sites - asking if item baselines the same)

```{r}
fit_scalar <- cfa(model_5_nocov, data = scores_wide_mat_z,
                  group = "site", std.lv = TRUE, missing = "fiml",
                  fixed.x = FALSE,
                  group.equal = c("loadings", "intercepts"))

# same issue as above - fewer than 10% have observed data for both variables in a pair
lavInspect(fit_scalar, "coverage")


anova(fit_metric, fit_scalar) # scalar invariance not supported

```

