```{r}
task_info <- tribble(
  ~item_task , ~task                    , ~task_category,
  "hf"       , "hearts & flowers"       , "executive function",
  "sds"      , "same & different"       , "executive function",
  "mg"       , "memory"                 , "executive function",
  "math"     , "math"                   , "math",
  "matrix"   , "pattern matching"       , "reasoning",
  "mrot"     , "shape rotation"         , "spatial cognition",
  "trog"     , "sentence understanding" , "language",
  "vocab"    , "vocabulary"             , "language",
  "tom"      , "theory of mind"         , "social cognition",
  "ha"       , "social attribution"     , "social cognition",
  "pa"       , "language sounds"        , "reading",
  "sre"      , "sentence reading"       , "reading",
  "swr"      , "word reading"           , "reading",
  "pa-es"    , "language sounds"        , "reading",
  "sre-es"   , "sentence reading"       , "reading",
  "swr-es"   , "word reading"           , "reading",
  "sre-de"   , "sentence reading"       , "reading",
  "swr-de"   , "word reading"           , "reading",
  "mefs"     , "MEFS"                   , "executive function"
)

task_metrics <- tribble(
  ~item_task,   ~metric_type,
  "hf"       , "ability",
  "sds"      , "ability",
  "mg"       , "ability",
  "math"     , "ability",
  "matrix"   , "ability",
  "mrot"     , "ability",
  "trog"     , "ability",
  "vocab"    , "ability",
  "tom"      , "ability",
  "ha"       , "prop_correct",
  "pa"       , "prop_correct",
  "sre"      , "guessing_adjusted_number_correct",
  "swr"      , "ability",
  "mefs"     , "standard_score"
)

cat_tasks <- c("swr")

run_info <- read_rds(here(glue("01_fetched_data/run_data.rds"))) |>
  select(site, dataset, language, task_id, variant_id, variant_name,
         user_id, run_id, adaptive, age, time_started)

score_files <- c("sumscores.rds", "roar_thetas.rds", "scores_custom.rds", "registry_scores.rds")
ref_sites <- c("pilot_uniandes_co", "pilot_mpieva_de", "pilot_western_ca")

scores <- score_files |>
  map(\(f) read_rds(here("02_scoring_outputs", "scores", f))) |>
  bind_rows() |>
  left_join(run_info) |>
  filter(site %in% ref_sites)

mefs <- read_rds(here("02_scoring_outputs", "scores", "scores_mefs.rds"))

scores_combined <- scores |>
  bind_rows(mefs) |>
  filter(!is.na(age)) |>
  filter(item_task != "ha") |>
  left_join(task_info)

task_scores <- scores_combined |>
  mutate(metric_type = if_else(str_detect(metric_type, "ability"), "ability", metric_type)) |>
  filter(!is.na(metric_value)) |>
  inner_join(task_metrics)

# cat_compare <- task_scores |>
#   group_by(item_task, run_id) |>
#   filter(task != "MEFS", n() > 1) |>
#   ungroup() |>
#   mutate(model_source = if_else(model_class == "CAT", "cat", "non_cat")) |>
#   select(site, task, run_id, model_source, metric_value) |>
#   pivot_wider(names_from = model_source, values_from = metric_value) |>
#   mutate(site_label = site |> fct_recode(!!!site_labels))
# 
# ggplot(cat_compare, aes(x = cat, y = non_cat, colour = site_label)) +
#   facet_grid(vars(site_label), vars(task)) +
#   geom_abline(color = "grey") +
#   geom_point(alpha = 0.3, size = 1) +
#   .scale_colour_site(guide = "none") +
#   labs(x = "CAT score", y = "Full model score")
# ggsave("cat_compare.png", width = 12, height = 3.5)

# remove CAT scores for rescored tasks
task_scores_uncat <- task_scores |>
  filter(item_task %in% cat_tasks | is.na(model_class) | model_class != "CAT")

# should be empty (i.e. each run has only one score)
# task_scores_uncat |> group_by(item_task, run_id) |> filter(n() > 1)

write_rds(task_scores_uncat, here("02_scoring_outputs/scores/scores_combined.rds"),
          compress = "gz")
```
